%%!TEX root = dissertation.tex
\setcounter{chapter}{3}
\chapter{The Structure of Voice Onset Time Variation in Bilingual Long-lag Stops}\label{ch4:uniformity}

\section{Introduction}\label{ch4:sec:intro}

One of the primary goals in this chapter is to investigate what languages can share in the mental representation of similar speech sound categories.\footnote{Note that ``similar'' is an often ill-defined concept that will be grappled with in Section \ref{ch4:sec:links}.} This focus ties into the main thread of the dissertation by addressing structure in phonetic variation at a linguistic level---sound categories. The idea of representation is intended here in the manner typically meant by psycholinguists \citep[e.g.,][]{llompart_2018_acoustic}, exemplar theory proponents \citep[e.g.,][]{amengual_2018_laterals}, and \citet{flege_2021_slmr} in their revised Speech Learning Model (SLM-r). These groups use similar language to describe representation, emphasizing distributions of sensory experiences rather than theoretical linguistic descriptions. For example, \citeauthor{flege_2021_slmr} describe the units of a multilingual segment inventory as categories comprising input distributions of exemplars: ``the sensory stimulation associated with...speech sounds that are heard and seen during production by others...in meaningful conversations'' \citeyearpar[][p. 32]{flege_2021_slmr}. The SLM-r also posits that the speech sounds of a bilingual's languages exist in a shared phonetic space, regardless of what they share in their representations. In starting with the SLM-r---where distributions of exemplars for different categories cohabit the same phonetic space---this chapter addresses the extent to which languages share representation(s). Much like Chapter \ref{ch3:voice}, the approach here is one of leveraging the structure of variation to understand the system. Additionally, as with the preceding chapters, this chapter focuses on the speech of early bilinguals, as discussed in Section \ref{ch1:sec:bilingualism}. This is an important reminder, as the conceptual model referenced throughout this chapter---\citeauthor{flege_2021_slmr}'s \citeyearpar{flege_2021_slmr} SLM-r---focuses more on the speech of second language (L2) learners and late bilinguals, as opposed to the early bilinguals in this dissertation. 

There are many pieces to this puzzle, and the literature has already addressed some of them. The introduction to this chapter proceeds as follows---Section \ref{ch4:sec:links} addresses which sound categories are candidates for shared representation for bilinguals in the first place and addresses key terminology, like ``similarity.'' Section \ref{ch4:sec:cli} builds on this by briefly summarizing the relevant crosslinguistic influence literature, addressing assimilation, dissimilation, and how they reflect on the idea of shared representation for sound categories. Section \ref{ch4:sec:uniformity} identifies a limitation of the existing paradigms in crosslinguistic influence and proposes adapting the uniformity framework as a way to fill the gap. This framework offers a way to interpret the structure of variation for a given acoustic dimension. Section \ref{ch4:sec:rqs} introduces the focus of this particular study---long-lag stops in Cantonese and English---and outlines the specific research questions and hypotheses. After Section \ref{ch4:sec:rqs}, the chapter moves onto methods and results in Sections \ref{ch4:sec:methods} and \ref{ch4:sec:analysisresults}.

\subsection{Identifying ``links'' across bilinguals' languages}\label{ch4:sec:links}

At first glance, the best candidates for shared representation are sound categories that are ``linked'' together. The definition of links, however, can be frustratingly vague in the multilingualism literature. In a handbook chapter on bilingual phonetics and phonology, \citeauthor{simonet_2016_bilingualism} describes ``links or connections of one sort or another between the phonetic categories'' \citeyearpar[][p. 10]{simonet_2016_bilingualism}. Despite being vaguely defined, links nonetheless represent a crucial concept. In the most basic sense, links are defined by the behavior they account for---they exist between sound categories that exert influence on one another under \textit{some} set of circumstances. This definition is somewhat problematic, as it would fail to identify (real) links in cases where influence is less likely to occur \citep[cf.][]{grosjean_2011_transfer}. Links behave dynamically, as such,  \citeauthor{simonet_2016_bilingualism} also notes that ``these connections...are transiently strengthened in contexts that induce the activation of both languages and inhibited in contexts that favor the use of only one of the languages'' \citeyearpar[][p. 10]{simonet_2016_bilingualism}. Arguably, such links must exist because crosslinguistic influence can be observed (this body of literature will be reviewed in Section \ref{ch4:sec:cli}). While there may be alternative explanations (i.e., global influence), the concept of links is widely assumed in accounting for bilinguals' behavior. 

\citet{flege_2021_slmr} expand on the idea of links in the SLM-r by providing a framework for predicting which sound categories will be linked together. The proposal is simple---namely, sound categories will be linked to the closest category in the other language. Determining which categories pair up, however, remains an empirical challenge from the perspective of speech production, and as a result, \citet{flege_2021_slmr} rely on perceptual metrics. This is not to say that either kind of metric is inherently better or worse, but rather, that perception- and production-based metrics offer different types of insight into the linguistic system. The reason for the challenge of pairing up sound categories is that perception and production do not always line up neatly. \citeauthor{flege_2021_slmr} assert that similarity ``must be assessed perceptually rather than acoustically because acoustic measures sometimes diverge from what listeners perceive'' \citeyearpar[][p. 33]{flege_2021_slmr}. The disconnect between the two processes arises from both linguistic and physiological bases. 

In an overview chapter on similarity in crosslinguistic influence, \citet{chang_2015_similarity} suggests an alternative---in accounting for behavior, similarity is best captured abstractly. \citeauthor{chang_2015_similarity} states that crosslinguistic influence at the segmental level tends to occur between sounds that share ``(1) similar positions in the respective phonemic inventories (when considering the contrastive feature oppositions---or, more broadly, the `relative phonetics'---of the sounds in relation to other sounds in the inventory), and (2) similar distributional facts'' \citeyearpar[][p. 201]{chang_2015_similarity}. While ``distributional facts'' seems to be intended in a broad sense, the example \citeauthor{chang_2015_similarity} gives is co-occurrence restrictions. This approach to similarity emphasizes a general role for abstraction but does not necessarily invite a formal phonological analysis. Developing such an analysis would likely constitute a dissertation in itself---\citet{mielke_2012_similarity} highlights the challenges of applying phonological features across languages, given the sheer variety of phonetics-phonology mappings in the world's languages. 

While \citet{flege_2021_slmr} and \citet{chang_2015_similarity} take different approaches---perceptual ratings and relative phonetics---they ultimately accomplish a similar goal, by accounting for abstraction and nonlinearity in listeners' mental representations. In sum, abstract similarity in the mind seems to be a prerequisite for the emergence of a link between two sound categories, given how it does a better job of accounting for when and where crosslinguistic influence occurs. The presence of abstract similarity, however, does not address what happens next. It does not entail any particular outcome, and it does not directly address how representation is structured for the sound categories in question. 

\subsection{Crosslinguistic influence and representation}\label{ch4:sec:cli}

The next step in the puzzle is understanding what happens to linked sound categories. The SLM-r outlines two primary outcomes for sound categories in a shared system---assimilation and dissimilation \citep{flege_2021_slmr}. Assimilation is a merging of phonetic properties and arguably occurs when bilinguals and learners do not ``discern a phonetic difference (or differences) between the realizations'' of sound categories \citep[][p. 40]{flege_2021_slmr}. It is not entirely clear at what level discernment between sound categories occurs, though it is most likely intended to be a linguistic level rather than a purely auditory one. Dissimilation, then, is the reverse---a diverging of phonetic properties that occurs when a difference is detected but is too small to maintain. These two processes are defined in rather absolute terms, which are tempered to some extent in the following paragraphs' continued discussion of the SLM-r. 

Notably, these processes need not impact all phonetic properties in the same way. For example, in a study of coronal stops produced by simultaneous French-English bilinguals, \citet{sundara_2006_production} found that bilinguals produced differences across languages for voice onset time (VOT) and the standard deviation of burst frequency. These bilinguals did not differentiate based on other spectral moments of the burst that monolingual comparison populations did, and as a result, \citet{sundara_2006_production} illustrate divergence on some properties and convergence on others. 

The motivation for the outcomes of assimilation and dissimilation arises from two simple constraints from the production and perception systems---effectively, do not get too close to each other in perception, and do not get too complicated in production \citep{guion_2003_systems, lindblom_1988_universals, flege_2021_slmr}. These constraints lead SLM-r to posit that proximity leads to instability, even if what counts as close for early bilinguals remains unclear. Bilinguals can, after all, perceive subtle acoustic differences between similar sound categories \citep{ju_2004_falling}. In SLM-r, the potential outcomes of instability are assimilation and dissimilation. Considering that bilinguals are fully capable of distinguishing highly similar sound categories across languages \citep[e.g.,][]{sundara_2006_production, lein_2016_vot, casillas_2021_interlingual}, this is not a trivial point to make. Yet, given SLM-r's primary focus on L2 learning, it is perhaps not a surprising approach. It may thus be more appropriate in the case of early bilinguals to also consider contrast maintenance alongside dissimilation. That is, early bilinguals may not need to assimilate or dissimilate a pair of similar sounds but rather simply maintain the subtle contrast as is. 

Following what SLM-r posits, a relatively simple account is that dissimilation for similar sound categories would lead to distinct representations of those categories and that assimilation leads to a shared representation. The picture is complicated, however, by the idea of imperfect assimilation and what \citeauthor{flege_2021_slmr} term \textit{composite categories}. Suppose sound categories from two languages are phonetically close to each other but do not fully assimilate. In that case, the SLM-r proposes that they will remain linked in a composite category ``defined by the statistical regularities present in the combined distributions of the perceptually linked...sounds'' \citep[][p. 41]{flege_2021_slmr}. This scenario might be characterized as imperfect or partially shared representation, where certain dimensions are kept apart, and others overlap. For example, the place of articulation may be shared across languages even if VOT differs---this scenario is observed by \citet{sundara_2006_production}, described above. Alternatively, the lack of clear-cut examples of assimilation in the literature may instead indicate that assimilation and dissimilation might be better cast as ends of a spectrum for a gradient, context-sensitive phenomenon. This re-conceptualization makes room for things like contrast maintenance and composite categories. 

There are a few potential reasons for the lack of clear-cut assimilation outside of late bilingual and L2 speech. First, true assimilation might just be rare in bilingual speech. This reason is supported by a recent meta-analysis of crosslinguistic influence for Spanish and English initial stop consonants \citep{casillas_2021_interlingual}. In this environment, English long-lag stops and Spanish short-lag stops are linked to one another \citep{fricke_2016_phonetic, goldrick_2014_switching, bullock_2009_sociophonetics, olson_2016_transfer}. \citet{casillas_2021_interlingual} found that early bilinguals did not produce ``compromise'' stop categories. That is, early Spanish-English bilinguals did not, on the whole, produce VOT that was somehow intermediate to the canonical productions by monolinguals of either language. Instead, crosslinguistic influence can be fully attributed to what \citeauthor{casillas_2021_interlingual} describes as ``performance category mismatches that result from dynamic phonetic interactions associated with language activation'' \citeyearpar[][p. 16]{casillas_2021_interlingual}. In this sense, the production of each category was influenced by task demands and factors such as social context. So while some assimilation occurs, it is far from the only process at play. This finding echoes arguments made by \citet{bullock_2009_sociophonetics} on the sophistication and control that bilinguals exert over their range of possible forms. So while there is clear evidence of a link between the two sounds---and perhaps even evidence for a composite category---``compromise'' seems inappropriate for capturing behavior. Instead, bilinguals produce a wide range of forms appropriate to and influenced by different contexts. Without considering task and context factors, it is perhaps not surprising for two sound categories to masquerade as a single composite category. 

A second reason for the rarity of complete assimilation arises from the experimental and corpus-based approaches typically used to study crosslinguistic influence. Experimental approaches to crosslinguistic influence use paradigms such as sentence reading, isolated word production, or picture naming---each paired with various common manipulations. At a more global scale, some studies set the language mode of the full session and compare individuals across sessions \citep{grosjean_2011_transfer, simonet_2019_convergence, sancier_1997_drift}, or compare groups of individuals in different language mode conditions \citep{antoniou_2010_context}. At a more local level, some experimental designs leverage language switching across blocks \citep{sundara_2006_production}, across trials \citep{goldrick_2014_switching}, or within trials \citep[i.e., prompted code-switching;][]{bullock_2009_sociophonetics, antoniou_2011_VOT, olson_2016_transfer}. Both types of experimental studies often include both cognate and non-cognate items as a focus or manipulation \citep[e.g.,][]{goldrick_2014_switching}. Corpus-based approaches similarly tend to focus on proximity to code-switching \citep{fricke_2016_phonetic, balukas_2015_vot} and cognate production \citep{brown_2015_finegrained}. Across all study types, there are common findings. Typically, cognates, words occurring before a language switch, and words produced in more bilingual modes show increased convergence. Conversely, unilingual modes, non-cognates, and words occurring far from a code-switch tend to show a greater degree of contrast maintenance (or divergence). While there is a tendency for convergence, \citet{bullock_2009_sociophonetics} demonstrate that proximity to a code-switch in a formal experimental setting leads some individuals to exaggerate the difference between English and Spanish VOT. This kind of linguistic behavior, arguably, reflects deep metalinguistic knowledge on behalf of bilinguals like those studied in \citet{bullock_2009_sociophonetics}.

In these approaches, the ability to examine crosslinguistic influence for any given pair of sounds hinges on the presence of an observable acoustic difference under some set of conditions. Arguably, for this reason, most prior work in crosslinguistic influence has focused on sounds that are phonologically similar (i.e., abstract, relative phonetics) yet phonetically distinct. A common example of this arises from languages that differ in their initial stop voicing contrasts. For example, as discussed at the beginning of this section, North American English contrasts long- and short-lag stops in initial position. Conversely, Spanish contrasts short-lag and prevoiced initial stops. Despite the clear difference in how languages encode a laryngeal timing contrast, there is nonetheless strong evidence for a crosslinguistic link between English long-lag and Spanish short-lag stops \citep{casillas_2021_interlingual, fricke_2016_phonetic, goldrick_2014_switching, bullock_2009_sociophonetics, olson_2016_transfer}. 

These studies demonstrate phonetic convergence---or variable assimilation---in two ways. First, VOT is shorter for English initial stops produced by bilinguals when compared to monolingual control groups. This result is attributed to the influence on English long-lag stops from the short-lag category in the other language \citep{olson_2016_transfer, johnson_2021_language}. Similarly, French-English bilinguals are more likely to produce lead voicing in initial English voiced stops compared to English monolinguals \citep{sundara_2006_production}. Second, evidence of crosslinguistic influence can also come from comparing bilinguals to themselves across different circumstances. For example, \citet{fricke_2016_phonetic} use a spontaneous speech corpus to demonstrate that Spanish-English bilinguals produce shorter, more Spanish-like VOT in the lead up to an English-to-Spanish code switch \citep{fricke_2016_phonetic}. An experimental example comes from \citet{simonet_2019_convergence}, where individuals participate in multiple sessions in which language mode is carefully controlled. While this body of work makes the presence of a link clear, it also highlights that there are distinct aspects of how these sound categories are represented in the bilingual mind \citep{casillas_2021_interlingual}. In the SLM-r, these examples might be considered composite categories. Alternatively, they might be examples of contrasts being maintained in the face of proximity.

In any case, this focus presents a conundrum. By using methods where observing degrees of similarity hinges on the ability to detect a difference, researchers often preemptively exclude some of the best candidates for shared representation---those that share both abstract \textit{and} acoustic similarity. While focusing on both is rare, it is not entirely absent from the literature. One example comparing highly similar sound categories in the early bilingualism literature comes from a lab-based study of Mandarin-English bilingual children \citep{yang_2019_vot}. The authors found that highly proficient bilingual 5 to 6-year-olds produced equivalent VOT for Mandarin and English long-lag stops, even though the monolingual comparison groups were consistently different. \citeauthor{yang_2019_vot}'s result suggests that the difference is either too small to maintain or that 5 to 6-year-old children have not yet mastered it. These claims should be tempered, however, as \citet{yang_2019_vot} did not control for language mode, and adult bilingual behavior was not considered. 

Despite some inroads, there is nonetheless a distinct paucity of work examining highly phonetically similar speech sounds across languages, even when such a connection would make sense. A recent study of crosslinguistic influence by \citet{tsui_2019_switching} compares English long-lag and Cantonese short-lag stop production in bilinguals. The study used a picture naming task in the context of a language switching design, where participants named pictures in both languages. The crucial comparison in the study is between trials that occurred immediately after a trial of the same language or the other language (i.e., whether there was a switch). While the design closely mirrored \citet{goldrick_2014_switching}, the results were murky---balanced bilinguals showed no evidence of crosslinguistic influence. The decision to use English long-lag and Cantonese short-lag stops as the stimuli could explain this outcome. This comparison reflects the need for stimuli to be acoustically distinct beforehand---as noted above---yet, it glosses over the fact that both languages contrast short-lag and long-lag VOT in initial position. The best candidates for links---and accompanying crosslinguistic influence---would be the long-lag stops in each language. The long-lag stops occupy the same relative position in their respective inventories and bear resemblance physically (e.g., see references in Section \ref{ch4:sec:rqs}). \citeauthor{tsui_2019_switching}'s \citeyearpar{tsui_2019_switching} null result with balanced bilinguals is thus unsurprising. 

This criticism suggests that \citep{tsui_2019_switching} would have gotten more insightful results by comparing Cantonese \textit{long-lag} stops to English long-lag stops. More importantly, however, it highlights the design constraints of the paradigms used in crosslinguistic influence research. Such methods are better suited for detecting links between acoustically distinct sound categories and documenting the circumstances that undergird parallel activation of languages. In \citeauthor{grosjean_2011_transfer}'s \citeyearpar{grosjean_2011_transfer} terms, these methods are best suited to detecting \textit{interference}, as opposed to \textit{transfer}. Interference is the kind of crosslinguistic influence observed between simultaneously activated mental representations---it is ephemeral, occurring ``online.'' Transfer, on the other hand, occurs on a longer time scale and affects the representations themselves. While \citet{grosjean_2011_transfer} argues that disentangling the two types of influence is difficult, the methods described above seem tailored more towards interference, given the way that they promote activation of both languages.

A good example of interference comes from Catalan-Spanish bilinguals' vowel production. \citet{simonet_2019_convergence} compare vowels on a within-talker basis from two separate sessions---unilingual Catalan and bilingual Spanish-Catalan---and found that Catalan /a/ was produced more like its Spanish counterpart in the bilingual session. While this result is straightforward, it is unique in that the authors show a dynamic within-talker process facilitated by language mode. In a monolingual setting, talkers maintain a contrast. However, the same talkers show partial assimilation in the bilingual setting. When both languages are activated, Catalan interferes with Spanish, leading to the observed outcome of phonetic convergence. \citet{simonet_2019_convergence} argue that these sounds are linked and thus simultaneously activated but ultimately have separate representations in long-term memory (i.e., do not reflect transfer). In its discussion of category formation, SLM-r seems more concerned with assimilation and dissimilation at the level of long-term representations \citep[i.e., transfer;][]{flege_2021_slmr}, even though more of the literature reviewed in support of the model uses designs that center interference. Notably, however, transfer and interference are difficult to disentangle \citep{grosjean_2011_transfer}.

To summarize, most work in crosslinguistic influence has focused on phonologically similar yet phonetically distinct pairs of segments and how they interfere with one another during the process of producing speech. These pairs are not strong candidates for transfer and shared mental representation (as defined at the beginning of this chapter). This widespread focus likely arises for several different reasons. The established paradigms---which greatly facilitate research---tend to require a detectable difference. It is also possible that assimilation in long-term mental representations is rare for early bilinguals, which would limit the options for studying such a phenomenon. Lastly, comparisons of categories that already exhibit both abstract and phonetic similarity may be taken for granted and not considered an interesting problem to focus on, despite the nature of the mental representation of sound categories being a key focus in psycholinguistics \citep{samuel_2020_resist}. 

While many psycholinguists are indeed concerned with representation, processing seems to have taken center stage in the psycholinguistics of bilingualism. In a prominent example of this, \citeauthor{fricke_2019_bilingualism} argue that ``bilingualism has the potential to reveal the fundamental breadth and underlying nature of variation in language processing'' \citeyearpar[][p. 204]{fricke_2019_bilingualism}. This chapter foregrounds the argument that bilingualism also offers a window into understanding the nature of mental representation. In the interest of understanding it, the best category candidates would be the hardest to distinguish using only surface forms.

\subsection{Adapting the uniformity framework}\label{ch4:sec:uniformity}

The study described in this chapter focuses on assessing whether phonetically similar sounds share a mental representation or not. Recall that mental representations are defined in psycholinguistic terms, as outlined at the beginning of this chapter. Unlike prior work focusing on variable convergence and divergence, this chapter addresses whether a single category is used in both languages or whether each language carries a separate representation of similar categories. Testing directly for shared structure in this way means that the set of methods that rely on detecting and modulating differences is not appropriate. To this end, this chapter extends the articulatory uniformity framework to the study of multilingual segment inventories. 

Articulatory uniformity is conceptualized as a constraint on within-talker phonetic variation, in which articulatory gestures or phonological primitives are implemented systematically in speech production \citep{chodroff_2017_structure, faytak_2018_uniformity, menard_2008_invariance}. The core idea of the articulatory uniformity framework is that phonetic variation is highly structured. While \citet{chodroff_2017_structure} draw tight connections between uniformity and phonological features, \citet{faytak_2018_uniformity} instead emphasizes how talkers learn and reuse articulatory gestures. This articulatory account builds on earlier work by \citet{menard_2008_invariance}, who argue that the stability of the first formant in French vowel production is best accounted for by stability in the tongue height gesture (i.e., reuse of the gesture). While the specific theoretical accounts vary somewhat by author, there is nothing to suggest that such accounts are incompatible with one another. Both articulatory and phonological explanations may be valid and even related to one another. Given the focus of this chapter on phonetic and psycholinguistic accounts of category formation and representation (rather than phonological), the articulatory account---with its accompanying acoustic consequences---is likely more appropriate, even if this dissertation does not directly engage with articulatory phonetics. 

In this light, if a set of segments share an attribute (i.e., share a description such as ``long-lag'' or belong to the same natural class), then talkers should implement the segments with the same phonetic target or articulatory gesture. This systematicity has been observed for vowel height \citep{menard_2008_invariance}, tongue shape \citep{faytak_2018_uniformity}, fricative peak frequency \citep{chodroff_inpress_sibilant}, and stop consonant VOT \citep{chodroff_2017_structure}. In the case of VOT in particular, the relationship between a laryngeal gesture and its acoustic consequence is clear. This allows for the extension of \citeauthor{menard_2008_invariance}'s \citeyearpar{menard_2008_invariance} argument regarding F1 and tongue height to VOT and its corresponding laryngeal gesture. Reusing the gesture across sounds that share the relevant attribute ``may simplify the somatosensory feedback needed to control the speech task`` \citep[][p. 26]{menard_2008_invariance}. In simple terms, reusing gestures is easier than the alternative---using different gestures---in the case of high vowels. The same argument could easily be extended to long-lag stops.

Findings for within-language stop consonant uniformity appear to be quite robust. \citet{chodroff_2017_structure} report consistent results across a lab study based on reading a list of CVC words and a corpus study comprising connected read speech. \citet{chodroff_2019_l2} replicate the uniformity findings for stop consonants with connected read speech samples from 140 non-native English speakers with a wide range of native languages in the ALLSSTAR corpus \citep{bradlow_2011_allsstar}. While \citet{chodroff_2019_l2} found a greater degree of between-talker variability with non-native speakers compared to the prior monolingual work \citep{chodroff_2017_structure}, the within-talker structure was robust. However, the uniformity framework has not yet been extended to early bilingual speech to compare how bilinguals produce phonetically similar sounds in each language. Extending the framework across languages follows the framing of uniformity as arising from articulatory reuse \citep{faytak_2018_uniformity}, effectively asking whether or not reuse extends across languages.

There is also motivation for uniformity in perception. As outlined in Section \ref{ch1:sec:processing}, \citet{orena_2019_identifying} speculated that a bilingual advantage at generalizing across languages in talker identification might derive from sensitivity to crosslinguistic structural similarity. While this remains speculation on behalf of crosslinguistic generalization, there is evidence that within-language uniformity facilitates talker identification, above and beyond typical talker-indexical components of a voice \citep{ganugapati_2019_structured}. It follows that this boon would also extend to bilingual talker identification, provided that phonetic variation across languages also exhibits uniform structure. 

\subsection{Long-lag stops in Cantonese and English}\label{ch4:sec:rqs}

English and Cantonese initial long-lag stops are strong candidates for shared mental representation because they exhibit both relative and physical phonetic similarity, akin to the difference for Mandarin and English in \citet{yang_2019_vot}.\footnote{Please refer to Tables \ref{ch3:tab:cantoneseinventory} and \ref{ch3:tab:englishinventory} in the previous chapter for a summary of the segmental inventories in both languages.} Consider the initial stop [k\textsuperscript{h}]---in citation speech---with a mean VOT of 80 ms in American English \citep{lisker_1964_vot} and 91 ms in Hong Kong Cantonese \citep{clumeck_1981_cantonese}. While these values are objectively different---though based on small sample sizes---it seems that using the same laryngeal timing gesture would be advantageous given the small difference across monolingual populations (that may or may not be perceptible). There is ample work documenting long-lag VOT across different varieties of English and speaking styles, with values as low as the 30--50 ms in spontaneous speech \citep{stuartsmith_2015_private}. There is far less work documenting Cantonese long-lag VOT; nonetheless, descriptive work casts it as having generic long-lag aspiration similar to English \citep{matthews_2013_cantonese, bauer_1997_cantonese, chan_2000_english, mielke_2018_voice}. For example, \citet{matthews_2013_cantonese} describe initial stops in both English and Cantonese as voiceless and aspirated, even though they differ in their phonological features---English is typically analyzed with a $\pm$voicing distinction and Cantonese with an $\pm$aspiration distinction \citep{matthews_2013_cantonese}.
 
While the presence of articulatory reuse within Cantonese and across languages remains an empirical question, it aligns with the finding that bilingual Mandarin-English children did not distinguish between languages in VOT \citep{yang_2019_vot}. Additionally, the predictions of the SLM-r \citep{flege_2021_slmr} suggest that long-lag items of minimally distinct VOT would assimilate or dissimilate but not be stable in such proximity. Thus, the present study asks: do Cantonese-English bilinguals uniformly produce long-lag stops within and across each of their languages? Leveraging the methodology from Chodroff and colleagues \citep{chodroff_2017_structure, chodroff_2018_predictability, chodroff_2019_l2} allows for a new perspective on the structure of variation and nature of mental representation in bilinguals' segment inventories. It also facilitates the study of phonetically similar speech sounds in ways that other paradigms do not. The hypothesis in this chapter was that bilinguals would indeed exhibit crosslinguistic uniformity and leverage articulatory reuse across Cantonese and English. 

\section{Methods}\label{ch4:sec:methods}

\subsection{Corpus}

This study uses the conversational interview recordings from the SpiCE corpus described in Chapter \ref{ch2:corpus}. As a reminder, the corpus comprises recordings of 34 early Cantonese-English bilinguals in both languages. The analysis in this chapter builds on the force-aligned phone transcripts. Please refer to Chapter \ref{ch2:corpus} for additional information about the talkers. 

\subsection{Segmentation and measurement}

All instances of prevocalic word-initial /p t k/ were identified from the conversational interview portion of the SpiCE corpus' force-aligned Praat TextGrid transcripts. The identification of tokens was based on the phone tier of the transcripts, and as a result, derives from the forced aligner's identification of stops given a lexical item and its entry in the pronunciation dictionaries. For English, only words with initial stress were included in the initial sample \citep{lisker_1967_some}.\footnote{\citet{chodroff_2017_structure} specifically excludes the extremely high-frequency English word ``to.'' The initial stress requirement implicitly accomplishes this here---while ``to'' only has one syllable, the most commonly used pronunciation variant in the dictionary is unstressed.} Code-switches out of the interview's primary language were not aligned, and as a result, they do not appear in the phone tier of the TextGrids. This limitation of forced alignment means that Cantonese /p t k/ were only considered if they occurred in the predominantly Cantonese interviews, and likewise for English. The initial total count of /p t k/ across talkers and languages included 10,428 tokens. 

While forced alignment performed reasonably well, anecdotally speaking, it was not perfect. Additionally, forced alignment includes both the closure and release of the stop in the marking of stop consonants. For these reasons, VOT estimates were refined using AutoVOT \citep{keshet_2014_autovot}---a command-line software tool that facilitates automated measurement of positive VOT. AutoVOT identifies the onset and offset of positive VOT within a specified window and with a minimum duration. Here, the minimum allowed VOT was set to 15 ms. This value was selected as the stops under consideration are all long-lag stops, and aspiration values under 15 ms are typical of short-lag stops \citep{lieberman_1988_speech}. The window used with AutoVOT was defined as the force-aligned segment boundaries plus or minus 31 ms \citep[as recommended by][]{chodroff_2017_structure}. If stops were too close for a 31 ms buffer, the onset of the second stop's window was set as the offset of the preceding window, as TextGrids do not permit overlapping intervals and AutoVOT uses the full TextGrid. This would occur, for example, in cases where a short vowel separates two stops, as may be the case in a phrase like ``too tall'' in running speech.

After running AutoVOT, instances of /p t k/ were subjected to exclusionary criteria to catch errors and exclude tokens immediately after a code switch. Tokens were excluded if there was substantial enough misalignment such that the AutoVOT offset did not fall within the original force-aligned boundaries of the word (n $=$ 567). Tokens were also excluded if the previous word was unknown (i.e., unintelligible or in a different language; n $=$ 263), if VOT was equal to the minimum value of 15 ms (n $=$ 446), or if tokens had a VOT more than 2.5 standard deviations above the grand mean ($>$ 129.5 ms; n $=$ 191), as in \citet{chodroff_2017_structure}.

Of the initial sample, 14.1\% was excluded, resulting in 8,961 stop tokens, summarized in Table \ref{ch3:tab:counts}. Talkers had a median of 97 Cantonese stops (range: 54--194) and 150.5 English stops (range: 73--540). Cantonese stops were culled at a slightly higher rate---they represent 43\% of the initial sample, but only 38\% of the final, post-exclusions sample. As there were comparable amounts of recorded speech in each language, the higher number of English stops in both the initial and final sample is likely due primarily to lexical distributional reasons. In addition to reporting on token frequency, Table \ref{ch3:tab:counts} also summarizes the number of word types for each of the segments in each language. 

Additionally, English has a greater number of highly frequent /k/-initial word types, while Cantonese /p/ occurs in fewer, less frequent word types in the final sample (n $=$ 60, max token frequency of 97) than English (n $=$ 158, max token frequency of 215). 

\begin{table}[htb]
  \caption{The number of stop tokens (overall and range across talkers) and word types for each language and sound category.}
  \label{ch3:tab:counts}
  \centering
  \begin{tabular}{lllll}
    \toprule
    \textbf{Language} & \textbf{Frequency} & \textbf{/p/} & \textbf{/t/} & \textbf{/k/} \\
    \midrule
    Cantonese         & Token (overall) & 374      & 1373         & 1688    \\
                      & Token (range)   & 0--32    & 17-79        & 19--116 \\
                      & Type (overall)  & 60       & 157          & 68      \\
    \midrule
    English           & Token (overall) & 1035     & 1336         & 3155   \\
                      & Range (tokens)  & 4--96    & 15--150      & 52--294 \\
                      & Type  (overall) & 158      & 143          & 208     \\
    \bottomrule     
  \end{tabular}
\end{table}

\section{Analysis and results}\label{ch4:sec:analysisresults}

The articulatory uniformity framework offers solid theoretical grounds for interpreting the structure of VOT variation within and across talkers. This analysis provides a qualitative description and quantifies that structure from a few different angles. Section \ref{ch4:sec:ordrel} describes the ordinal relationship between each of the segments across talkers and languages (i.e., how they are ordered by VOT). Section \ref{ch4:sec:correlations} reports on a series of pairwise correlations of talker means for each of the three segments in each language. Lastly, Section \ref{ch4:sec:lmem} comprises the results of a Bayesian mixed-effects model aimed at elucidating the role of language while accounting for variables known to impact VOT.

\subsection{Ordinal relationships}\label{ch4:sec:ordrel}

Prior work with lab and read speech strongly suggests an expected ordinal relationship for VOT across places of articulation, in which /p/ is consistently shorter than /k/ and where /t/ falls in the middle. The argument for this widely attested pattern is based on vocal tract aerodynamics and articulatory constraints \citep{cho_1999_vot}. One of the major contributions of \citet{chodroff_2017_structure} is that these ordinal relationships are much more constrained than would be expected from a purely ordinal perspective. Ordinal relationships are a starting place, and they represent just one piece of the puzzle. 

The results presented in this section suggest that \textit{puzzle} is an appropriate characterization, as talkers largely did not adhere to the expected order. While there is some reason to expect coronals not to pattern accordingly in English, as \citet{chodroff_2017_structure} review literature indicating coronal behavior to be more variable across dialects of English, the relationship between /p/ and /k/ is inconsistent across talkers in the SpiCE corpus. Table \ref{tab:ordrel} reports the proportion of talkers whose mean VOT values followed the expected /p/ $<$ /t/ $<$ /k/ relationships. Note that one talker (VM25A) did not have any instances of Cantonese /p/ in the final sample. The unexpected results were as follows. Cantonese /t/ is typically longer than Cantonese /p/---the opposite holds for English. Cantonese /k/ tends to be longer than Cantonese /t/, but this is almost never the case for English. The ordering of /p/ and /k/ is a toss-up in both languages. 

Prior work with English connected speech reports rates of adherence in the 80-90\% range for all pairwise combinations, with the exception of /t/ $<$ /k/ being drastically lower for native English speakers in \citet{chodroff_2019_l2}. While the English /t/ $<$ /k/ comparison is remarkably low here at 6\%, only the English /p/ $<$ /t/ ordering falls in the range that prior work suggests, at 82\%. This lack of adherence is apparent in the relative ordering or markers in Figures \ref{ch4:fig:ordrelvf} and \ref{ch4:fig:ordrelvm}, which depict the mean and standard error of VOT for each segment, language, and talker. The goal of Figures \ref{ch4:fig:ordrelvf} and \ref{ch4:fig:ordrelvm} is to showcase the variety of patterns across individuals and to highlight that a single summary plot of means only would be inappropriate. In many cases, the standard errors for the different segments in a given talker's panel overlap, as is the case for VM21B in Figure \ref{ch4:fig:ordrelvm}. Such overlap in the standard errors indicates that strict ordering may not be appropriate here, as there is not a great deal of confidence in the means' ordering. Additionally, talkers do not appear to be consistent across languages. For example, talker VF19B in Figure \ref{ch4:fig:ordrelvf} exhibits a clear /p/ $<$ /t/ $<$ /k/ relationship in Cantonese, but a clear /p/ $<$ /k/ $<$ /t/ relationship in English. In fact, only three talkers in the corpus exhibit the same pattern of means across languages (VM21B, VM23A, and VM25A).

\begin{table}[hb!]
\caption{Proportion of talker means that adhered to expected ordinal relationship for VOT: /p/ $<$ /t/ $<$ /k/ mean VOT durations. Note that talker VM25A has no instances of Cantonese /p/ in the final sample.}
  \label{tab:ordrel}
  \centering
  {\small
  \begin{tabular}{llllll}
    \toprule
    \textbf{Language} & \textbf{/p/$<$/t/} & \textbf{/t/$<$/k/} & \textbf{/p/$<$/k/} & \textbf{/p/$<$/t/$<$/k/} &  \textbf{n} \\
    \midrule 
    Cantonese   & 0.24  & 0.61  & 0.39  &  0.15 & 33 \\
    English     & 0.82  & 0.06  & 0.47  &  0.00  & 34 \\
    \bottomrule
  \end{tabular}
  }
\end{table}

\begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=0.9\linewidth]{figures/ch4_ordrel_vf_5in.png} 
  \caption{This figure depicts the ordinal relationships for the female talkers. Each panel depicts the mean VOT and standard error for VOT for each segment, with E(nglish) and C(antonese) in separate rows.}
  \label{ch4:fig:ordrelvf}
  \end{center}
\end{figure}

\begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=0.9\linewidth]{figures/ch4_ordrel_vm_5in.png} 
  \caption{This figure depicts the ordinal relationships for the male talkers. Each panel depicts the mean VOT and standard error for VOT for each segment, with E(nglish) and C(antonese) in separate rows. VM25A had no /p/ tokens. }
  \label{ch4:fig:ordrelvm}
  \end{center}
\end{figure}

\subsection{Pairwise correlations}\label{ch4:sec:correlations}

To examine the relationship between stops within and across languages, 15 pairwise Pearson's \textit{r} correlations were calculated using talker means. Each correlation compares talkers means for two different segments. The full set of pairwise correlations includes three within English, three within Cantonese, and nine comparing English to Cantonese. These correlations are reported along with Holm-adjusted \textit{p}-values to account for multiple comparisons. This analysis uses the \textit{psych} \citep{revelle_2021_psych} package in R \citep{r_2021}. As in \citet{chodroff_2017_structure}, this correlation analysis aims to elucidate within-talker invariance and between-talker variability. Tight correlations for between-talker means signals within-talker invariance, while a wide spread between points signals between-talker variability. While using means ignores information about within-category variability---a major shortcoming of this approach---prior work sets up strong, clear expectations about the pattern of mean values for long-lag VOT \citep{chodroff_2017_structure, cho_1999_vot}. The mixed-effects analysis in the following section takes this variation into account.

Table \ref{ch4:tab:correlations} summarizes the output of all 15 correlations in text form. Figure \ref{ch4:fig:correlations1} depicts the six within-language correlations and Figure \ref{ch4:fig:correlations2} depicts the across-language correlations. While there is some evidence for both within- and across-language structured variation, the correlations reported here are considerably lower than prior work on English read speech, where within-language comparisons had \textit{r} $>$ 0.7 \citep{chodroff_2017_structure, chodroff_2019_l2}. With the exception of the English /p/ $\sim$ /k/ (\textit{r} $=$ 0.70, \textit{p} $<$ 0.001), all of the correlations here were either moderate (0.5 $<$ \textit{r} $<$ 0.7; \textit{p} $<$ 0.01; n $=$ 6) or weak and non-significant (n $=$ 8). Within-English correlations were the most consistent---all three had \textit{r} at or above 0.65 (p $<$ 0.001). Of the within-Cantonese correlations only /p/ $\sim$ /t/ was significant (\textit{r} $=$ 0.59; \textit{p} $=$ 0.003). This disparity across English and Cantonese for the same set of talkers highlights the need to study a variety of typologically distinct languages to understand how the structure of variation \textit{varies}.

\begin{table}[htbp]
  \caption{All 15 correlations are based on raw mean VOT---and separately, residual VOT after accounting for speaking rate---for each talker, language, and segment. Each row indicates the comparison, Pearson's \textit{r}, and the Holm-adjusted \textit{p}-value given 15 comparisons.}
    \label{ch4:tab:correlations}
    \centering 
    \scriptsize
    \begin{tabular}{ll|ll|ll}
      \toprule
      &   & \multicolumn{2}{l|}{\textbf{Raw}} & \multicolumn{2}{l}{\textbf{Residualized}} \\
      \textbf{Type}   & \textbf{Comparison}  & \textit{r} & \textit{p} & \textit{r} & \textit{p}  \\
    \midrule
    Within-Cantonese  & Cantonese /p/ $\sim$ Cantonese /t/    & 0.59    & 0.003       & 0.59   & 0.003    \\
    Within-Cantonese  & Cantonese /p/ $\sim$ Cantonese /k/    & 0.44    & 0.08        & 0.55   & 0.01     \\
    Within-Cantonese  & Cantonese /t/ $\sim$ Cantonese /k/    & 0.38    & 0.11        & 0.34   & 0.21     \\
    \midrule
    Within-English    & English /p/   $\sim$  English /t/     & 0.65    & $<$0.001    & 0.63   & 0.001    \\
    Within-English    & English /p/   $\sim$  English /k/     & 0.70    & $<$0.001    & 0.70   & $<$0.001 \\
    Within-English    & English /t/   $\sim$  English /k/     & 0.66    & $<$0.001    & 0.60   & 0.002    \\
    \midrule
    Across-language   & Cantonese /p/  $\sim$ English /p/     & 0.62    & 0.001       & 0.57   & 0.01    \\
    Across-language   & Cantonese /t/  $\sim$ English /t/     & 0.40    & 0.11        & 0.35   & 0.21    \\
    Across-language   & Cantonese /k/  $\sim$ English /k/     & 0.57    & 0.004       & 0.54   & 0.01    \\
    \midrule
    Across-language   & Cantonese /p/  $\sim$ English /t/     & 0.41    & 0.11        & 0.29   & 0.31    \\
    Across-language   & Cantonese /p/  $\sim$ English /k/     & 0.40    & 0.11        & 0.29   & 0.31    \\
    Across-language   & Cantonese /t/  $\sim$ English /p/     & 0.43    & 0.08        & 0.37   & 0.20    \\
    Across-language   & Cantonese /t/  $\sim$ English /k/     & 0.37    & 0.11        & 0.27   & 0.31    \\
    Across-language   & Cantonese /k/  $\sim$ English /p/     & 0.58    & 0.003       & 0.59   & 0.003   \\
    Across-language   & Cantonese /k/  $\sim$ English /t/     & 0.38    & 0.11        & 0.37   & 0.20    \\
    \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=0.9\linewidth]{figures/ch4_correlations1_5in.png} 
  \caption{Correlations for within-language pairwise comparisons of raw mean VOT are depicted with points representing talker means for the segments on the x and y axes and superimposed regression lines. The margins display histograms for each of the axes. Within-Cantonese comparisons are depicted in black, and within English comparisons in purple. \textit{Note that while some of the distributions in the margins appear different, they are not. This is an artifact of plotting the same distribution on different axes in different plots---they only appear mirrored.}}
  \label{ch4:fig:correlations1}
  \end{center}
\end{figure}

\begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=0.9\linewidth]{figures/ch4_correlations2_5in.png} 
  \caption{Correlations for the across-language comparisons of raw mean VOT are depcited in the same manner as Figure \ref{ch4:fig:correlations1}. Comparisons at the same place of articulation are depicted in pink, and comparisons at different places of articulation are in orange.} 
  \label{ch4:fig:correlations2}
  \end{center}
\end{figure}

Two of three across-language correlations at the same place of articulation were significant, with moderate \textit{r} values (/p/ $\sim$ /p/: \textit{r} $=$ 0.62, \textit{p} $=$ 0.001; /k/ $\sim$ /k/: \textit{r} $=$ 0.57, \textit{p} $=$ 0.004). Notably, the correlation for /t/ $\sim$ /t/ was not significant (\textit{r} $=$ 0.40, \textit{p} $=$ 0.11). Of the across-language comparisons that do not share a place of articulation, only one was significant---Cantonese /k/ $\sim$ English /p/ (\textit{r} $=$ 0.58, \textit{p} $=$ 0.003). Again, /t/ is absent here.

\citet{chodroff_2017_structure} also repeat the correlation analysis in a way the coarsely accounts for speaking rate. This consideration is important, as the local speaking rate is known to influence long-lag VOT in spontaneous speech \citep{stuartsmith_2015_private} and because prior work demonstrates both talker and language effects on speech rate \citep{bradlow_2017_rate}. In comparing the two versions of the correlation analysis, \citeauthor{chodroff_2017_structure} found that ``the magnitudes of the correlations among voiceless stops did not deviate from the original magnitudes, demonstrating that differences among talkers in the realization of these sounds cannot be reduced to talker-specific speaking rates'' \citeyearpar[][p. 34]{chodroff_2017_structure}. 

A similar analysis was done here, using means calculated over \textit{residual} VOT values from a simple linear regression in which VOT was predicted by average phone duration within the word. Average phone duration is a proxy for speech rate. It was calculated as the difference between the word's AutoVOT-estimated onset and force-aligned offset, divided by the number of segments in the canonical form of the word.\footnote{The canonical form was pulled from the pronunciation dictionaries used during forced alignment. In cases where there was more than one form in the dictionary, the entry with the higher number of phones was used.\label{ch4:foot:canonical}} The results---Pearson's \textit{r} and Holm-adjusted \textit{p} values---are reported in the rightmost columns of Table \ref{ch4:tab:correlations}. Qualitatively, the results mostly mirror the correlations based on raw VOT, though there are some minor differences in significance and magnitude. Both versions of the analysis support a conclusion in which the patterns are weak overall.

While these relationships indicate some degree of articulatory reuse, the overall picture is far from compelling, particularly when considered alongside the analysis of the ordinal relationships in Section \ref{ch4:sec:ordrel}. Compared to prior work, these correlations are less consistent and generally weaker, indicating that the uniformity constraint discussed in Section \ref{ch4:sec:uniformity} may not be as robust as previously argued. This point will be returned to in this chapter's discussion (Section \ref{ch4:sec:discuss}).

The next steps in \citeauthor{chodroff_2017_structure}'s \citeyearpar{chodroff_2017_structure} methods focus on validating the strength of the correlations. Their approach includes estimating confidence intervals for the correlations using a bootstrap procedure. In a later paper, \citet{chodroff_2019_covariation} simulate what would emerge from a purely ordinal relationship (i.e., a system where the only requirement was the relative VOT ordering of segments) between stops and demonstrate that the observed correlations are much stronger---ultimately arguing for a uniformity constraint on phonetic variation. Given that the correlations found in this chapter are drastically lower and largely do not adhere to the expected ordinal relationships, the remainder of this analysis takes a different approach.

\subsection{Linear mixed-effects model}\label{ch4:sec:lmem}

The analysis in this section leverages a Bayesian multilevel linear model to elucidate the sources of variation within and across talkers. As Bayesian modeling emphasizes the estimation of effect magnitudes, the model can be used to assess how talkers' sound categories compare to one another while simultaneously accounting for factors known to influence long-lag VOT, such as speaking rate and prosodic position. This section builds on the frequentist mixed-effects model analysis in \citet{chodroff_2017_structure}. Also, this modeling approach is more in line with the generative modeling approach advocated for by \citet{haines_2020_theoretically}---in a way that the correlation and ordinal relationships analyzed in the preceding sections are not. Specifically, this approach retains the variation lost when working with means and also uses a response variable distribution that aligns with the constraints of the variable in question. 

This section proceeds as follows. First, Bayesian modeling and Bayesian inference are described in broad terms. References are provided that point the reader to further reading on the topic. Second, the structure of the model used in this chapter is described and motivated. Lastly, the results of the model are reported. All code used in this analysis is available on GitHub, at \url{https://github.com/khiajohnson/dissertation}.\footnote{Note that this repository is currently private.}

\subsubsection{Bayesian inference}

The corpus sample was analyzed with a Bayesian linear mixed-effects model using the brms package in R \citep{burkner_2017_brms, r_2021}. The brms package provides a simple, formula-based interface to Stan---a widely used probabilistic programming language for estimating Bayesian statistical models via Hamiltonian Monte Carlo and No-U-Turn Sampling \citep{stan_2021}. Bayesian models are desirable in the case of modeling multilingual VOT for both practical and theoretical reasons. Practically, they are not subject to the convergence problems that plague comparable frequentist models. Theoretically, they allow for graded statements regarding the strength of evidence for all parameters, both population-level (i.e., fixed effects) and group-level (i.e., random effects) parameters, as well as derived parameters (e.g., some combination of existing parameters). While there are many other benefits, readers are referred to \citeauthor{vasishth_2018_bayesian}'s \citeyearpar{vasishth_2018_bayesian} recent in-depth tutorial paper on Bayesian modeling in the phonetic sciences for further argumentation. 

Inference in Bayesian models is based on the posterior distributions of parameters in the model, which reflect the range and probability of credible values for parameters. The posterior combines information from prior knowledge and the likelihood of observing the data given the specified model. While some Bayesian models use detailed and specific prior knowledge, it is perhaps more common to use weakly informative, regularizing priors \citep{gelman_2017_prior}, which constrain the parameter space to possible values and down weight extreme or unlikely values, while also not biasing the model toward any specific outcome. The model described in the next section uses regularizing priors. 

While Bayesian modeling typically emphasizes parameter estimation in a probabilistic framework, there are decision criteria that facilitate hypothesis testing. One such technique is to use \citeauthor{kruschke_2011_rope}'s \citeyearpar{kruschke_2011_rope} ROPE+HDI method. The ROPE is a ``region of practical equivalence'' surrounding the null value. HDI stands for highest density interval, and it is typically used to describe Bayesian posterior distributions. \citeauthor{kruschke_2011_rope}'s \citeyearpar{kruschke_2011_rope} decision criterion is simple: if the HDI falls entirely within the ROPE, then the null value can be accepted; if the HDI falls entirely outside the ROPE, then it can be rejected; if there is overlap, then a decision should be withheld. In the case of standardized data, \citet{kruschke_2011_rope} recommends the convention of setting a ROPE to be [$-$0.1, 0.1]---half the size of a small Cohen's \textit{d} effect. This decision criterion provides a useful scaffolding for interpreting the magnitudes of standardized effects when presented alongside the posterior distributions. 

\subsubsection{Modeling multilingual VOT}

VOT was modeled using a Bayesian linear mixed-effects model. The model used in this section is provided in Equation \ref{ch4:num:formula}, below. While the model is not the maximal model, it instead follows guidelines for parsimonious model building, in which the parameters of direct interest are included as random slopes, and the controlling parameters are not \citep[see:][]{barr_2013_maximal, bates_2018_parsimonious}. The controlling parameters are only included as population-level ``fixed'' effects.

One of the main benefits of multilevel modeling is partial pooling, where information for different levels of a variable is shared across those levels. \citeauthor{mcelreath_2020_sr} argues that ``any batch of parameters with exchangeable index values can and probably should be pooled [where exchangeable] just means the index values have no true ordering'' \citeyearpar[][p. 435]{mcelreath_2020_sr}. Pooling can be done for both intercepts and slopes, which in turn allows both to vary by group. While Bayesians tend to refer to the random effects structure in terms of partial pooling, it is important to note that partial pooling and random effects refer to the same thing, regardless of whether the analysis is frequentist of Bayesian. 

The model was specified as follows. First, Equation \ref{ch4:num:formula} gives the formula used in \textit{brms}. Immediately afterward is a description of the model's parameters and how they were specified. 

\begin{equation}
  \begin{aligned}\label{ch4:num:formula}
    \text{VOT } \sim \text{ 1 } + \text{ Place } \times \text{ Language } + \text{ Average Phone Duration } + \text{ Pause } + \text{ } \\
    (\text{1 } + \text{ Place } \times \text{ Language }|\text{ Talker}) + (\text{1 }| \text{ Word})
  \end{aligned}
\end{equation} 

\begin{description}
  \item[VOT] was the dependent variable---it was standardized (i.e., centered and scaled) in order to facilite the specification of priors and a ROPE. 
  \item[Place] encodes place of articulation for the stops and has three levels. Following \citet{chodroff_2017_structure}, Place was weighted effect coded in order to account for unequal sample sizes across the three levels and to faciliate the interpretation of the simple effects in light of the interaction term \citep{brehm_2021_contrasts}. Specifically, weighted effect coding ensures that a simple effect is equivalent to what the main effect would be in a model without the interaction. Coding was implemented using the \textit{wec} R package \citep{nieuwenhuis_2017_weighted}, and leads to reporting Place effects for T (weights: /p/ $=-1.92$, /t/ $=1$, /k/ $=0$) and K (weights: /p/ $=-3.44$, /t/ $=0$, /k/ $=1$).  
  \item[Language] is a binary variable that encodes whether the VOT measurement comes from an English or Cantonese word. As with Place, Language was also weighted effect coded (weights: Cantonese $=-1.61$, English $=1$).
  \item[Average Phone Duration] represents the average duration of phones within the word. It was calculated as the difference between the word's AutoVOT-estimated onset and the force-aligned word offset, divided by the number of segments in the canonical form of the word (see Footnote \ref{ch4:foot:canonical}). As noted in Section \ref{ch4:sec:correlations}, average phone duration serves as a proxy for local speaking rate. A word-internal measure is desirable here, as many tokens were preceded by a pause and thus lack the necessary preceding context to calculate the speaking rate. Average phone duration was standardized (i.e., centered and scaled). 
  \item[(Preceding) Pause] is a binary variable that indicates whether or not the token occurred after a pause or not. Pauses were identified using the force-aligned transcripts and include instances where the preceding phone was ``sil'' (silence) or ``sp'' (silent pause). Pause was also implemented with weighted effect coding (weights: False $=-0.33$, True $=1$).
  \item[Word] indicates the word that the VOT measurement comes from. 
  \item[Talker] indicates which of the 34 talkers produced the item.
\end{description}

The interaction for Language $\times$ Place was included in the model---it directly addresses the research question relating to whether or not bilinguals maintain a difference across languages for these sounds. Additionally, the model includes partial pooling (i.e., random intercepts) for Word and Talker, as well as for the Language, Place, and Language $\times$ Place terms (i.e., random slopes). 

As noted above, the priors were set to be weakly informative and regularizing, motivated by the discussions in \citet{gelman_2017_prior} and \citet{mcelreath_2020_sr}. Specifically, the priors were set as follows.

\begin{description}
  \item[Intercept] Student's \textit{t} distribution with $\nu = 3$, $\mu = 0$, and $\sigma = 2.5$
  \item[Population-level parameters] Normal distribution with $\mu = 0$ and $\sigma = 1$
  \item[Group-level standard deviations] Half Student's \textit{t} distribution with $\nu = 3$, $\mu = 0$, and $\sigma = 2.5$
  \item[Group-level correlations] LKJ distribution with $\eta=2$
\end{description}

The model was fit using four chains with 5,000 iterations (2,500 warmup) for a total of 10,000 post-warmup samples. The chains were well-mixed, based on a visual inspection of trace plots, a lack of divergent transitions, and \textit{\^{R}} values below 1.05. Additionally, the effective sample size was sufficiently large for all parameters \citep[for discussion, see][]{vasishth_2018_bayesian}.

\subsubsection{Results}

A summary of the model's population-level parameters is provided numerically in Table \ref{ch4:tab:poppar} and visually in Figure \ref{ch4:fig:poppar}. The population parameters indicate that VOT is modulated by language, local speaking rate, and the presence of a preceding pause. Recall that the categorical population-level parameters were weighted effect coded---this facilitates the interpretation of simple effects in the presence of interaction terms.

The overall effect of Language indicates that English long-lag stops were produced with longer VOT than Cantonese ($\beta =$ 0.16, 98.9\% HDI outside ROPE). The effect of Place is not consistently modulated by Language, as both of the Place $\times$ Language interaction terms overlapped substantially with the ROPE. This interpretation is not, however, supported by the model predictions summarized in Figure \ref{ch4:fig:conditionaleffects}, which shows the conditional effects for Place and Language---that is, the predicted means for each of the six combinations. The predictions look exactly as would be expected in the case of an interaction---the distance between means is absent for /p/, larger for /t/, and still larger for /k/. That this doesn't emerge in the parameter summary in Figure \ref{ch4:fig:poppar} and Table \ref{ch4:tab:poppar} may be due to how the categorical variables were coded. In cases such as these, \citet{mcelreath_2020_sr} argues that parameter summaries are often less informative (and useful) than model predictions. 

To dig into this interaction and justify its inclusion in the model, a second model was fit without the interaction term. All other aspects were identical to the model described in Equation \ref{ch4:num:formula}. The models with and without the interaction were then compared using the expected log pointwise predictive density \citep[ELPD][]{vehtari_2017_practical}, as implemented in the \textit{loo} R package \citep{vehtari_2020_loo}. The result of this comparison demonstrates the importance of the interaction term---it substantially improves the model's predictive accuracy (ELPD difference: $-$13.4, SE difference: 5.7). This result suggests that the interaction visible in the model's predictions in Figure \ref{ch4:fig:conditionaleffects} is valid, even if the parameterization of the population-level variables does not show such an outcome. 

Returning to a summary of the original model, the control parameters behaved as expected. VOT was longer when the local speaking rate was slower. This effect is captured by the relatively high posterior mean for Average Phone Duration ($\beta =$ 0.32, 100.0\% HDI outside ROPE). VOT was also longer after a pause, though the effect size was considerably smaller than for speaking rate ($\beta =$ 0.12, 94.0\% HDI outside ROPE).

\begin{table}[htbp]
  \caption{Population parameter summary.}
    \label{ch4:tab:poppar}
    \centering 
    \footnotesize
    \begin{tabular}{lccc}
    \toprule
    \textbf{Parameter}         & \textbf{Est.} &  \textbf{95\% HDI} & \textbf{\% Outside ROPE} \\
    \midrule
    Intercept                             &  0.18   & [0.09, 0.28]  & 95.1 \\
    Place (T)                             &  0.05   & [-0.03, 0.13] & 11.1 \\
    Place (K)                             & -0.02   & [-0.07, 0.03] & 0.1  \\
    Language (English)                    &  0.16   & [0.11, 0.21]  & 98.9 \\
    Average Phone Duration                &  0.32   & [0.30, 0.34]  & 100.0 \\
    Preceding Pause (True)                &  0.12   & [0.09, 0.16]  & 94.0 \\
    Place (T) $\times$ Language (English) & -0.01   & [-0.07, 0.04] & 0.2 \\
    Place (K) $\times$ Language (English) &  0.04   & [0.00, 0.08]  & 0.3 \\
    \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=\linewidth]{figures/ch4_poppar_5in.png} 
  \caption{This figure depicts the 95\% HDI posterior distributions for each of the population-level parameters, with the posterior mean indicated by the dot. The orange shaded section represents the ROPE. Recall how to interpret ROPEs---accept the null if posterior is fully within bounds and reject it if the posterior is fully outside ROPE; otherwise, withhold a decision.}
  \label{ch4:fig:poppar}
  \end{center}
\end{figure} 

\begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=0.8\linewidth]{figures/ch4_conditionaleffects_4in.png} 
  \caption{This figure depicts the model's predicted value and standard error of the predicted value for each of the places of articulation by language, using the fitted method in \textit{brms}' conditional effects function. Notably, the error overlaps almost completely for /p/, but not at all for /t/ and /k/.}
  \label{ch4:fig:conditionaleffects}
  \end{center}
\end{figure}

While the main takeaway from the population parameters is the difference in VOT across languages, the model also offers insight into the sources of variation in this population. A summary of the variability in the model's grouping parameters is provided numerically in Table \ref{ch4:tab:grppar} and visually in Figure \ref{ch4:fig:grppar}. The largest source of variability in the model is in the Word intercepts ($\beta=$ 0.44). The second-largest source of variability is in the Talker intercepts ($\beta=$ 0.25). While there is variability across talkers in the random slopes, few are meaningfully different from the corresponding population-level parameters---this is evident in Figure \ref{ch4:fig:grpparvar}, which depicts the by-Talker intercept and slope deviations from the model. The intercept can be interpreted as the model estimate when all parameters are at their zero value---in the case of continuous parameters, this is zero, while in the case of the categorical variables, it is the weighted grand mean. The intercepts in \ref{ch4:fig:grpparvar} thus reflect individuals' deviations from this overall intercept. A sizable plurality of talker intercept posterior distributions falls outside of the ROPE, while the vast majority of the by-talker slopes overlap substantially or fall entirely within the ROPE. In line with \citet{chodroff_2017_structure}, this result highlights between-talker variability and within-talker stability. 

\begin{table}[htbp]
  \caption{Group parameter variability summary.}
    \label{ch4:tab:grppar}
    \centering 
    \footnotesize
    \begin{tabular}{llll}
    \toprule
    \textbf{Group}  &\textbf{Parameter S.D.} & \textbf{Est.} &  \textbf{95\% HDI} \\
    \midrule
    Word    & Intercept                             & 0.44 & [0.40, 0.50] \\
    \midrule
    Talker  & Intercept                             & 0.25 & [0.19, 0.32] \\
    Talker  & Place (T)                             & 0.09 & [0.05, 0.14] \\
    Talker  & Place (K)                             & 0.06 & [0.04, 0.09] \\
    Talker  & Language (English)                    & 0.08 & [0.05, 0.11] \\
    Talker  & Place (T) $\times$ Language (English) & 0.05 & [0.02, 0.08] \\
    Talker  & Place (K) $\times$ Language (English) & 0.04 & [0.02, 0.06] \\
    \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=\linewidth]{figures/ch4_grppar_5in.png} 
  \caption{This figure depicts the posterior distributions for the standard deviation of each of the grouping parameters, both intercepts and slopes.}
  \label{ch4:fig:grppar}
  \end{center}
\end{figure}

\begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=0.85\linewidth]{figures/ch4_grpparvar_5in.png} 
  \caption{This figure depicts the 95\% HDI for each talker across the talker intercepts and by-talker slope terms. The shaded orange interval represents the ROPE.}
  \label{ch4:fig:grpparvar}
  \end{center}
\end{figure}

At first glance, the results of the mixed-effects model are puzzling in how they seem to contradict what is apparent in the raw data described and analyzed in Sections \ref{ch4:sec:ordrel} and \ref{ch4:sec:correlations}. While there seems to be a cross-language difference in VOT for /t/ and /k/, the model here suggests there is more uniformity than those analyses would support. Why? Given the uncontrolled and spontaneous nature of this speech data, and the large amount of variability captured in partial pooling for words, a simple answer to this question is that talkers simply use different words. To test this, a third model was fit without Word intercepts (but otherwise identical to Equation \ref{ch4:num:formula}). Qualitatively, the exclusion of Word intercepts drastically changes the model output. All of the remaining standard deviation parameters increased---the standard deviations for Talker intercepts and slopes for Place, Language, and Place $\times$ Language interaction. Additionally, the interaction between Place and Language predicted by the original model disappears. Without partial pooling for words, only the difference between English and Cantonese /t/ remains. These differences indicate that the apparent discrepancy between the mixed-effects model and the ordinal and correlational analyses can be explained via differences in word distributions across talkers. Essentially, talkers vary in the words they use, and this variation may render the results of Sections \ref{ch4:sec:ordrel} and \ref{ch4:sec:correlations} somewhat misleading. 

\section{Discussion}\label{ch4:sec:discuss}

This chapter reports on a study of long-lag stops in Cantonese-English bilingual speech from the SpiCE corpus described in Chapter \ref{ch2:corpus}. It leverages the uniformity framework to assess VOT similarity within and across languages from a few different angles---via ordinal relationships, pairwise correlations, and a Bayesian linear mixed-effects model. In broad strokes, the evidence for uniformity both within and across languages was somewhat mixed. Yet, uniformity was apparent in the mixed-effects model---along with a clear crosslinguistic difference---which is arguably the most robust and reliable of the methods used here \citep{haines_2020_theoretically}. 

An analysis of ordinal relationships between the duration of mean VOT for talkers in each language was inconclusive. Talkers largely did not adhere to the expected order, and further, talkers were not internally consistent across languages. This counters prior work establishing strong rates of adherence. However, the difference may be attributable to speaking style. Most of the work documenting ordinal relationships among mean stop VOT is based on isolated word production and read speech \citep[e.g.,][]{chodroff_2017_structure, cho_1999_vot, lisker_1964_vot}. In this body of work, \citet{chodroff_2017_structure} found weaker correlations in reading compared to isolated word production, indicating that speech style plays a role. The yet weaker correlations in this chapter could be interpreted as extending that pattern to a more casual style. Another possible (complementary) account of the results in this chapter is one based on distributions of words produced by the talkers. Both isolated word production and reading offer tight control over the words produced, which means that the distribution of words produced is constant across talkers. The same cannot be said of spontaneous speech, in which talkers produce different words and utterances over the course of conversational interviews. The mixed-effects model in Section \ref{ch4:sec:lmem} highlights how this is a crucial difference across talkers in this chapter. In this sense, speaking style is an important factor, as it impacts both form and content. 

The correlation analysis offers a slightly more nuanced take on structure, and in doing so, provides evidence for within-language and, to a lesser extent, across-language uniformity. Across the board, the correlation magnitudes were weak or moderate, which differs from the strong and clear within-English patterns observed in prior studies \citep{chodroff_2017_structure, chodroff_2019_l2}. The within-English comparisons were consistently moderate and significant, which replicates prior work. The within-Cantonese and across-language comparisons do not offer nearly as clear a picture. While there is some evidence of structure, particularly for /p/ and /k/ across languages, the evidence for tightly structured variation is far from compelling. This result was surprising, given the typological survey of VOT relationships in \citet{chodroff_2019_covariation}, which found uniform structure at the level of languages. Recall that the prediction for this chapter included both within-language and across-language uniformity. 

While the murky outcome of the ordinal relationships and correlational analyses was largely unexpected, observing a different outcome for a different speech style is not without precedent. For example, the correlation magnitudes that \citet{chodroff_2017_structure} found for connected, read speech were not as strong as those for isolated word production. It follows that an even less formal connected speech style would lead to even weaker relationships---likely because of an increase in variability. Attending to speaking style is likely one of the main factors accounting for why lab and corpus results often differ \citep{gahl_2012_reduce,chodroff_2017_structure}; and, similarly, for corpus studies of monolingual and bilingual speech \citep{johnson_2019_probabilistic}. 

The Bayesian mixed-effects model offers insight into sources of variation, including the specific role that language and place of articulation play in accounting for VOT variation. The model showed a clear difference in VOT by language, with English VOT being consistently longer for /t/ and /k/. While the introduction to this chapter reported on prior work indicating Cantonese might be longer \citep{clumeck_1981_cantonese, lisker_1964_vot}, those numbers were not necessarily appropriate for the speaking style of the SpiCE corpus, particularly given the differences in English VOT across styles \citep{stuartsmith_2015_private}. Interestingly, the model showed a consistent difference across languages for VOT, and very few talkers deviated from this overall pattern in a meaningful way. This result suggests that the population-level account provides an appropriate generalization across talkers. While there is precedent for languages having different long-lag VOT settings \citep{chodroff_2019_covariation}, it is not immediately clear \textit{why} English and Cantonese, in particular, would show different patterns on a within-speaker basis. It could be due to lexical distributional reasons, broad language timing differences, or underlying representational differences---such explanations would be mere speculation at this point. A much greater amount of variation in the model is captured by variable intercepts for word and talker. The model, then, supports the argument for uniformity---between-talker differences vary drastically, while talkers tend to be more internally consistent. Internal consistency, in this case, seems to be more on a ``macro'' level. That is, talkers with longer /p/ VOT tend to also have longer /t/ and /k/ VOT in both languages \citep[as with speech rate in][]{bradlow_2017_rate}. This kind of macro internal consistency says nothing about the specific ordinal relationships across languages or sound categories, just the general ballpark that VOT production falls into. This macro level, however, may ultimately be what listeners have access to for talker identification---this idea will be expanded upon in the next paragraph. 

In light of the evidence for uniformity, the small but consistent difference across languages is worth some attention. While Section \ref{ch4:sec:lmem} models standardized VOT, back-transforming the value into the original units suggests a difference across languages of approximately 4 ms. This is a relatively small difference, yet, it is worth flagging that this kind of difference is often smallest in spontaneous speech compared to lab speech. Regardless, a difference of this magnitude is not likely to be perceptible in categorization (and similar) paradigms. Work by \citet{mcmurray_2002_gradient}, however, demonstrates a gradient and fine-grained effect of processing VOT in increments as small as 5 ms. In this study, \citeauthor{mcmurray_2002_gradient} monitor participants' eye moments in an experiment using the visual world paradigm to ascertain how small VOT differences impact lexical access. The crucial result is participants access the correct word, but that modulating within-category VOT impacted processing difficulty. Further, as research on mergers in sound change has demonstrated, individuals do not always perceive differences that they produce \citep{yu_2019_individual, cheng_UR_production}. As such, perception may not be the best indicator of whether or not this size difference is meaningful in practice. If this difference is indeed meaningful and bears out in future work, it carries implications for how similar sound categories are represented and discussed in the literature. If talkers can maintain such small distinctions across languages, it would reiterate the rarity of assimilation for early bilinguals and necessitate a broader version of models like SLM-r, that account for a wider variety of multilingual backgrounds. This conclusion essentially questions whether full assimilation actually occurs in the speech of early bilinguals, and as a result, questions its utility for this kind of population. Partial and context-dependent assimilation (i.e., due to interference) seem to be more fruitful directions.

Another possibility is that the underlying laryngeal gesture is ``the same'' but subject to global language timing factors. That is, talker-internal and language-internal factors both influence how VOT manifests. The study in \citet{bradlow_2017_rate} offers an example of this dual influence in the case of speech rate, using native and non-native speech from the ALLSSTAR corpus. In this study, \citeauthor{bradlow_2017_rate} demonstrate that talkers who speak faster in their first language (L1) tend to also speak similarly fast in their L2. As this study examined a wide variety of L1s (the L2 was always English), \citeauthor{bradlow_2017_rate} also demonstrate differences across languages, with some L1s tending to be slower and others faster. This interpretation could be applied fairly transparently to the study in this chapter: talkers with long VOT in one language would also have long VOT in the other language, even if they maintain a difference between languages. 

Yet another possibility is that the VOT specification may be even more distinct underlyingly (i.e., $>$ 4 ms) but ultimately brought closer together by the bilingual language mode of the SpiCE interviews. While the interviews were set up such that sentence reading and storyboard narration tasks preceded the conversational interviews (see Section \ref{ch2:sec:design}), and thus helped talkers get into the language mode of the interview, the context is nonetheless bilingual---it promotes a bilingual language mode \citep[see][]{grosjean_2011_transfer}. In this context, observing a meaningful difference across languages for VOT suggests that under different circumstances, such a difference might be more pronounced. While this account seems to contradict the one offered in the preceding paragraph, it does not specify where the difference arises from---it could be in the representation of VOT and/or in timing factors. The accounts are thus not necessarily contradictory.

The results presented in this chapter provide some support for a crosslinguistic uniformity constraint, in addition to providing an empirical description of bilingual long-lag stops. The weaker (or merely ``macro'') constraint on within-talker variability compared to prior work has implications for representation and perception. Tracking a uniformity-like pattern has been proposed as a mechanism for rapidly adapting to speech across languages \citep{reinisch_2013_retune}, and in multilingual talker identification \citep{orena_2019_identifying}. Further, uniformity in structure is useful for talker identification within a single language \citep{ganugapati_2019_structured}. While these accounts are straightforward to interpret in the context of clear and strong relationships, the chapter raises questions about how useful fine-grained structure is in the case of spontaneous speech. It would be worth exploring in future work whether the ``macro'' structure discussed above is sufficient to confer a benefit in talker identification or if the tight structure of uniformity is necessary. Given the presence of macro structure in the results---as well as the importance of salient factors like pitch \citep[over more subtle factors;][]{perrachione_2019_judgments}---it seems that macro structure might be sufficient. If this interpretation stands in perception, it would lend insight and nuance into the utility of uniformity as a perceptual strategy in real communicative contexts. 

Overall, this chapter highlights the need to study spontaneous speech and demonstrates the utility---and some limitations---of the uniformity framework for better understanding crosslinguistic similarity. This chapter also provides evidence for the speculations about what drives multilingual talker identification \citep{orena_2019_identifying} outlined in Section \ref{ch1:sec:processing}.


\endinput % -------------------------------------------------------- %





















% THE GRAVEYARD OF WORDS


% Define representation, phonetic categories, and exemplar-y model, what it means for categories to be linked, i.e., the composite category of SLM-r

% A consequence of bilingualism is that individuals must navigate overlapping segment inventories. This paper is concerned with what languages share, if anything, in the mental representation of speech sound categories. As representation means different things across linguistic disciplines, defining and situating the term is first necessary. The approach in this chapter largely falls out of the revised Speech Learning Model \citep[SLM-r;][]{flege_2021_slmr} and its exemplar-flavored take on what phonetic categories look like in linguistic systems with more than one language. 

% SLM-r is a widely used and respected model used in second language acquisition and multilingualism research. Unlike some other models in the same space, SLM-r grapples with both perception and production. SLM-r assumes that speech sound categories from different languages exist in a shared phonetic space and are subject to constraints from the perceptual and productive systems. Effectively, don't get too close to each other in perception, and don't get too complicated in production \citep{guion_2003_systems, lindblom_1988_universals, flege_1995_slm}. These constraints lead SLM-r to posit that proximity leads to instability, even if what counts as close remains unclear. Considering how bilinguals are fully capable of maintaining subtle distinctions for similar sound categories across languages \citep[e.g.,][]{sundara_2006_production}, this is not a trivial point to make. 

% So, what does representation look like in this system? SLM-r outlines a few potential outcomes for sound categories in a shared system—they can assimilate or dissimilate. A relatively simple take on this is that assimilation equals shared mental representation, while dissimilation equals separate. The picture is complicated, however, by the idea of imperfect assimilation and what \citeauthor{flege_2021_slmr} term \textit{composite categories}. In the SLM-r, if sounds from two languages are phonetically too close to each other, they will remain linked in a composite category "defined by the statistical regularities present in the combined distributions of the perceptually linked...sounds." \citep[][p. 41]{flege_2021_slmr}. This scenario might be characterized as an imperfectly shared representation, where certain dimensions are kept apart, and others overlap. This particular characterization is salient in a recent meta-analysis of crosslinguistic influence for Spanish and English initial stop consonants. In this study, \citet{casillas_2021_interlingual} found that early bilinguals did not produce ``compromise'' stop categories. That is, early Spanish-English bilinguals did not produce voice onset time that was somehow intermediate to canonical productions by monolinguals of either language. This finding echoes arguments made by \citet{bullock_2009_sociophonetics} on the sophistication and control that bilingual exert over their possible forms. There is no compromise but rather a wide range of forms that bilinguals can deploy according to context.

% % Need to fix a lot in here because Casillas paper really goes against the idea of composite or "compromise" categories

% This idea of composite categories is similar to other concepts in multilingualism literature, namely that of linked categories. While the idea is pervasive, it is somewhat vaguely defined. In a handbook chapter on bilingual phonetics and phonology, \citet{simonet_2016_bilingualism} describes ``links or connections of one sort or another between the phonetic categories'' (p. 10). \citeauthor{simonet_2016_bilingualism} then notes that ``these connections...are transiently strengthened in contexts that induce the activation of both languages and inhibited in contexts that favor the use of only one of the languages'' \citeyearpar[][p. 10]{simonet_2016_bilingualism}. Presumably, sound categories could be linked whether they surface in dissimilated or composite (assimilated) forms. The idea behind composite categories is more fully fleshed out and theoretically useful than mere links in grappling with how representation works in the bilingual mind. 

% Most prior work in crosslinguistic influence has focused on sounds that are phonologically similar yet phonetically distinct. A common example of this arises from languages that differ in their initial stop voicing contrasts. North American English contrasts long- and short-lag stops in initial position. Conversely, Spanish (among many languages) contrasts short-lag and prevoiced initial stops. As will become apparent later in the introduction, there is strong evidence for a crosslinguistic link between English long-lag and Spanish short-lag stops, despite the clear difference in voice onset time. The relative position of these sounds within each language can account for why they are linked together; in each case, the linked sound occupies the position closest to long-lag, on a spectrum ranging from long-lag to short-lag to prevoiced. The primacy of ``relative phonetics'' was put forth in \citeauthor{chang_2015_similarity}'s \citeyearpar{chang_2015_similarity} chapter on similarity in bilingual phonetics and phonology. \citeauthor{chang_2015_similarity} argues that crosslinguistic influence at the segmental level tends to occur between sounds that share ``(1) similar positions in the respective phonemic inventories (when considering the contrastive feature oppositions---or, more broadly, the `relative phonetics'---of the sounds in relation to other sounds in the inventory), and (2) similar distributional facts'' \citeyearpar[][p. 201]{chang_2015_similarity}. This approach to similarity emphasizes a general role for abstraction but does not necessarily invite a formal phonological analysis. In a similar vein, \citeauthor{flege_2021_slmr} argue that similarity ``must be assessed perceptually rather than acoustically because acoustic measures sometimes diverge from what listeners perceive'' \citeyearpar[][p. 33]{flege_2021_slmr}. At this point, ``relative phonetic'' and perceptual similarity seem to be a prerequisite for considering a link between two sound categories and can be used to account for when and where crosslinguistic influence occurs. It does not outline what happens after sounds are ostensibly linked to one another nor opine on the nature of representation for the sound categories in question. 

% \citeauthor{flege_2021_slmr} make a clear appeal to phonetic similarity for assessing assimilation. This appeal is evident in how it steps back from making phonological arguments in general and in its exemplar-flavored account. The SLM-r posits that sound categories ``are defined by the statistical properties of input distributions'' \citeyearpar[][p. 40]{flege_2021_slmr}. In the case of assimilation, there is a single distribution for both languages---a shared representation. Composite categories are considered a special type of assimilation in the SLM-r, though given the results of \citeauthor{casillas_2021_interlingual}'s \citeyear{casillas_2021_interlingual} meta-analysis, they may not be an appropriate characterization of early bilinguals' systems. In the case of dissimilation, the sound categories move apart and comprise separate distributions---separate representations. While \citeauthor{flege_2021_slmr} argue that crosslinguistic influence provides a diagnostic to test for the presence or absence of dissimilation, but also state that ``A method did not exist in 1995 for determining when a new L2 phonetic category had been formed and, alas, the same holds true today'' \citeyearpar[][p. 41]{flege_2021_slmr}. It can be surmised from this that crosslinguistic influence is not a perfect diagnostic. 

% % the flow is off in this part

% In any case, the focus on distributions of experienced exemplars fits in well with the psycholinguistics literature that argues for the primacy of position-specific allophones \citep{mitterer_2018_allophones}, against the use of phonological features in accounting for speech behavior \citep{llompart_2018_acoustic}, and against equating theoretical categories with mental categories more broadly \citep{samuel_2020_resist}.

% The theoretical framework adopted here leans much harder into the phonetics side of the equation and takes exemplar-style sound categories for position-specific allophones as the level of abstraction. The specific categories considered in this chapter are likely subject to some form of assimilation. One of the questions taken up in this chapter is whether this assimilation is complete or takes the form of a composite category. In all cases, crosslinguistic influence---phonetic similarity or dissimiarily---for linked sounds is measured by comparing distributions of measurements, typically in the context of null hypothesis significance testing. The following paragraphs provide a review of the literature on crosslinguistic influence for stop consonants. 


% %Phonetic similarity is typically assessed by distilling either the entire signal () or a subset of relevant acoustic dimensions () and measuring the distance between relevant categories (e.g., Euclidean distance). Applying phonetic versions of similarity to bilingualism is straightforward, though it assumes that the measures used are appropriate in both languages. On the other hand, phonological similarity is typically assessed through distributional () or feature-based mechanisms (). Translating these phonological metrics to a bilingual system, however, is complicated. It requires making a multitude of assumptions about the nature of each language's inventory and ensuring some form of shared currency (i.e., a feature set). 

% % Define phonological similarity, and phonetic similarity, and what it means to be phonologically similar, but arise from a different part of the mental space, again i think exemplars and composite categories are the way to go here


% \hl{intro drafted up to here}

% More in depth review of CLI work -->
% One example is the comparison between initial voiceless stops in English (long-lag) and Spanish (short-lag). Despite the substantial phonetic differences, these sounds are clearly linked in the bilingual mind \citep{fricke_2016_phonetic, antoniou_2010_context, goldrick_2014_switching, sundara_2006_production}. 

% The following studies focus on telling initial stops apart when the stops under consideration are short-lag and long-lag stops, respectively. In most cases, the difference in voice onset time arises because the languages considered are English and a language with a different initial voicing contrast, as with the example given earlier in this chapter. 

% \hl{summary of lab CLI here} \citep{fricke_2016_phonetic, antoniou_2010_context, goldrick_2014_switching, sundara_2006_production}. % add more!

% These studies demonstrate phonetic convergence---or assimilation---in two ways. First, VOT is shorter for English initial stops produced by bilinguals when compared to monolingual control groups. This result is attributed to the influence on English long-lag stops from the short-lag category in the other language. Second, bilinguals appear more likely to produce lead voicing in initial English voiced stops compared to English monolinguals \citep{sundara_2006_production}. In both cases, evidence of crosslinguistic influence arises from comparing bilinguals to monolinguals. Corpus research demonstrates that Spanish-English bilinguals produce shorter, more Spanish-like VOT in the lead up to an English-to-Spanish code switch \citep{fricke_2016_phonetic, bullock_2009_sociophonetics}. 

% The studies mentioned so far focus on VOT, but represent a small subset of the crosslinguistic influence literature. There are many examples of contrasts that are maintained across languages, yet still subject to crosslinguistic influence---for example, with vowels \citep{guion_2003_systems}, laterals \citep{amengual_2018_laterals,barlow_2014_aoa}, and fricatives \citep{peng_1993_influence}). % flesh this paragraph out, and describing how the work on other speech sound is relevant to the quesitons here, noting that in some cases the choice of acoustic measures is more challenging 

% The ability to examine crosslinguistic influence between phonetically and/or phonologically similar sounds hinges on the presence of an observable difference under some set of conditions. This observable difference could take any number of forms---acoustic, gestural, or cognitive (i.e., retrieval time). The sounds typically selected are not discussed as being the same---phonetic character choice notwithstanding. As such, links tend to be described as connecting similar and subject-to-influence sounds that ultimately have distinct representations in either the phonetics, the phonology, or both \citep{antoniou_2010_context,simonet_2016_bilingualism,bullock_2009_sociophonetics}. In the revised Speech Learning Model (SLM-r) \citep{flege_2021_slmr} introduced earlier, these examples would be considered composite categories---combined distributions of phonetic information from linked categories that presumably retain ``peaks'' for each language. While composite categories are widely attested, there are fewer good examples of full category convergence, at least in the early bilingualism literature. One example comes from a lab-based study of Mandarin-English bilingual children in which highly proficient 5--6 year olds did not differ in VOT across Mandarin and English long-lag stops, despite differences across the monolingual comparison groups \citep{yang_2019_vot}. This suggests that the difference is either too small to maintain or that 5--6 year old children have not yet mastered it. The claims in \citep{yang_2019_vot} should be tempered, however, as language mode was not well-controlled for and adult bilingual behavior was not considered. % Describe more examples of full convergenge.

% Despite some inroads, there is nonetheless a distinct paucity of work examining highly phonetically similar speech sounds across languages, even when such a connection would make sense. A recent study of crosslinguistic influence in Cantonese-English bilinguals compares English long-lag and Cantonese short-lag stops in the context of a language switching paradigm \citep{tsui_2019_switching}. While this comparison clearly reflects the need for stimuli to be acoustically distinct beforehand, it glosses over the fact that both languages contrast short-lag and long-lag VOT in initial position. The best candidates for linkages---and accompanying crosslinguistic influence---should be the long-lag stops in each language. The null result with balanced bilinguals is thus unsurprising. This is not to suggest that the \citep{tsui_2019_switching} would have gotten more insightful results by comparing long-lag to long-lag, but rather to highlight that paradigms designed to modulate crosslinguistic influence tend to focus on \textit{telling things apart}, as opposed to \textit{telling things together}. % Describe telling things together more clearly
 