%%!TEX root = dissertation.tex
\setcounter{chapter}{2}
% \setcounter{page}{1}
\chapter{The structure of acoustic voice variation in bilingual speech}
\label{ch3:voice}

\section{Introduction}\label{ch3:sec:introduction}


How does voice vary across a bilingual's two languages? This question sets the stage for this chapter. But first, it is important to consider what voice is and does. Voices provide considerable information about the person talking, ranging from their current physical and emotional state to talker indexical features that help listeners identify who they are \citep{podesva_2015_voice}. In this context, voices can be described as auditory faces---they are uniquely individual yet share basic characteristics with the broader population \citep{belin_2004_voice}. Where faces share an overall shape and composition of features (e.g., eyes, nose, etc.), voices share the acoustic consequences of similar vocal anatomy. Yet, at the same time, when you see a familiar face or hear the voice of a person you know, you can often immediately recognize who it is, as well as ascertain some information about their present state. In this way, both voices and faces signal identity along with their physical and emotional state. 

Along with all of this information, voices simultaneously convey a communicative message. While ``body'' is perhaps an oversimplicfication---it is used to evoke identity in addition to the physical body---\citeauthor{podesva_2015_voice} discuss voice as a ``bridge between body and language'' \citeyearpar[][p. 175]{podesva_2015_voice}. Disentangling such information and understanding the structure of voices is no small feat---it means understanding how listeners leverage variable vocal dimensions to process talker-indexical, affective, social, and linguistic information. This feat also presents a processing challenge---one that arises from the sheer variability within and across voices. 

Though voices share some attributes---such as in how spectral shape, noise, and formants pattern---they also vary in unique ways \citep{lee_2019_acoustic}. From the perspective of voice perception, the balance between shared and idiosyncratic characteristics makes some amount of sense. The shared dimensions allow listeners to recognize the sound they hear as a voice, and they also help listeners perceive, classify, and understand new voices. Idiosyncrasies, on the other hand, enable identification and discrimination between different voices. While this makes sense conceptually, understanding the structure of voice variation in speech production and its complement in listeners' ability to process that information remains an active area of research. 

The focus of this chapter is acoustic voice variability, and the emphasis on describing and processing variation echoes one of the big puzzles in phonetics: the ``lack of invariance'' problem \citep{liberman_1967_perception}. Given the ubiquity of variation, the lack of invariance problem asks how perceivers can efficiently extract relevant and important information from the communicative signal---whether that information relates to the talker, message, or some other dimension \citep{kleinschmidt_2018_sociolinguistic}. This chapter focuses on variation in speech production, particularly as it relates to talker identity and the analogy of voices as auditory faces. By foregrounding the speech signal itself, this chapter effectively asks what is available in the speech signal for listeners to use in voice identification. While this dissertation does not include perception research---and as a result, will not be able to comment on what listeners use---it generates hypotheses about perception that are grounded in the information comprising the speech signal.

While variation is indeed wide-ranging, it remains far from random. Some prevalent accounts of how individuals understand and process variation emphasize its structure \citep[e.g.,][]{chodroff_2017_structure, lee_2019_acoustic}. While this chapter looks at the structure of voices and the following chapter examines sound category structure, both attempt to elucidate structure in the speech signal that may be beneficial for listeners in understanding and processing new talkers. 

\subsection{Voice and voice quality}\label{ch3:sec:voicequality}

While the previous section sets the stage for voice and variation broadly, this section approaches voice from the bottom up. In the narrowest sense, voice has been defined by the behavior of the vocal folds---the source---though even with this narrow definition, \citet{garellek_2019_voice} acknowledges that the acoustic and perceptual consequences of the source cannot be separated from supralaryngeal factors (i.e., the filter). 

Voices are multidimensional and can vary on a vast array of different dimensions. While early work focused on how different articulatory settings correspond to voice quality \citep{laver_1980_phonetic, pittam_1987_lts}, more recent accounts advocate for a psychoacoustically informed model \citep{kreiman_2014_theory}. The rationale for this shift arises from the observation that there is not a one-to-one mapping from articulation to perception via acoustics, as discussed in detail by \citet{garellek_2019_voice}, in his recent review chapter on the phonetics of voice. In any case, both approaches reflect the wide range of dimensions. The behavior of fundamental frequency---including its absence---captures \citeauthor{garellek_2019_voice}'s articulatory categories of vocal fold approximation, voicing, and rate of vibration. Voice quality is captured acoustically by spectral shape and noise parameters (to be reviewed in detail in Section \ref{ch3:sec:acoustic}) and articulatorily by constriction degree, irregularity, and tension. 

While \citeauthor{garellek_2019_voice}'s \citeyear{garellek_2019_voice} chapter focuses on voice and voice quality in the domain of linguistic contrast and variation, the psychoacoustic model of voice quality he references accounts for voice more broadly---it also captures filter behavior via formants \citep{kreiman_2014_theory}. 

As touched on in the first paragraph of this chapter, there is also a large body of work highlighting the many different things that voice indexes---affect, stance, psychological states, behavior, physical characteristics, and identity \citep{podesva_2015_voice}. Identity here includes the idea of ``linguistic identity,'' which stems from early work summarizing how ``phonetic settings'' vary across languages and dialects \citep[see][]{podesva_2015_voice, pittam_1987_lts,mennen_2010_settings}. So while the acoustic and articulatory dimensions noted above vary for linguistic reasons, the same set can also vary for non-linguistic reasons. The same set thus indexes a multitude of different things simultaneously. This observation is especially relevant in light of Kreiman and colleagues' argument that their perceptually validated set of dimensions are more than the sum of their parts \citep{kreiman_2014_theory, kreiman_2021_validating}. Voice quality and what it indexes thus form a many-to-many relationship, where measures covary and conspire together to form a multidimensional percept of voice. 

\subsection{Structure in voice quality variation}

There is a large body of literature focused on understanding differences in variability across populations for a small set of these acoustic measurements. Such studies typically compare summary statistics for fundamental frequency (F0) and a handful of spectral measures. This body of work is summarized in Section \ref{ch3:sec:clxcomparisons} in the context of crosslinguistic comparisons. Before summarizing this work, it is important to highlight that very little of it dives into the \textit{structure} of voice variability, which is a relatively new area spearheaded by Lee and colleagues \citep{lee_2019_acoustic, lee_2019_spontaneous, lee_2020_language}. In this set of studies examining acoustic voice variation in different languages and speech styles, Lee and colleagues leverage the psychoacoustic model of voice quality \citep{kreiman_2014_theory} and adapt methods from the domain of face variability and perception \citep{burton_2016_faces}. Their driving question is one of understanding the structure of acoustic information in the speech signal. As noted in Section \ref{ch3:sec:voicequality}, acoustic dimensions do not behave in isolation; rather, they pattern together in complex ways. Part of what is novel about \citeauthor{lee_2019_acoustic}'s approach is that it gets at how these variables behave in relation to one another or how such covariation is structured. In many ways, this is the first step towards understanding which aspects of voice are available to listeners and thus useable in perceptual processes, particularly when coarse summary statistics (i.e., means, ranges, and standard deviations) do not indicate cross-talker differences. 

To drill down into the structure of voice variability, \citet{lee_2019_acoustic} use a series of principal components analyses (PCAs) to investigate how acoustic measurements pattern with one another. PCA is a dimensionality reduction technique---that is, a large set of variables are distilled into components that reflect covarying bundles of variables. The methods used in this study will be described in greater detail in Section \ref{ch3:sec:pca}. In their original paper, \citet{lee_2019_acoustic} examined the structure of variability on a within-talker basis as well as across the larger speech community represented within the University of California, Los Angeles Speaker Variability Database \citep{keating_2019_database}. This database includes English recordings and force-aligned transcripts of 201 talkers completing 12 different tasks ranging from scripted to unscripted. Talkers were all UCLA students, varying in their language background (i.e., whether or not English is their L1) and sex (here, male or female). Crucially for the comparison with their later work, \citet{lee_2019_acoustic} focused on relatively small samples of sentence reading from within this corpus. 

The takeaway from this work is that different voices share structure with each other and the group as a whole. \citet{lee_2019_acoustic} reach this conclusion by analyzing the configurations and variance accounted for by principal components across talkers. Shared structure takes the form of components with the same variables accounting for comparable amounts of the overall variation. That is, sharing structure means the same set of variables covarying with one another. The most commonly shared component consisted of higher spectral slope and noise variables and accounted for approximately 20\% of the overall variance. These variables are associated with vocal breathiness or brightness. The next most commonly shared component comprised higher formant variables and accounted for approximately 10\% of the overall variance. These variables are typically associated with vocal tract size and speaker identity. Despite this shared structure, however, \citet{lee_2019_acoustic} argue that the rest of voice structure variation is largely idiosyncratic. 

\citet{lee_2019_spontaneous} replicate this work with short samples of spontaneous speech from the same database. The results were similar, with the exception that F0 emerged as a shared relevant dimension. This result arguably reflects the difference between reading and spontaneous spoken English, with reading tending to be more monotonous and spontaneous speech exhibiting more affective qualities. In spontaneous speech, F0 varies along with the higher source spectral shape and noise parameters. In read English speech, F0 likely varies quite a bit less. \citet{lee_2020_language} replicates this work again with sentence reading in Seoul Korean, again finding minimal differences that are explained readily by typological differences from English. Unlike English, F0 and variability in the lower formants emerged as relevant dimensions in read Korean speech. The authors argue that this reflects phrasal intonation patterns that occur in Korean reading. 

Conceptualizing what these dimensions mean and how to think about acoustic voice variability in this way is challenging, as many of the acoustic dimensions considered do not map neatly onto a single percept. F0 is a straightforward example, given its clear relationship to pitch. Many of the spectral measures, both harmonic and noise-based, are much more challenging to interpret without considering multiple measures simultaneously. \citet{garellek_2019_voice} gives an example of this in how spectral shape needs to be interpreted in the context of spectral noise. For example, lower spectral shape indicates a more creaky voice quality, while higher spectral shape indicates a more breathy voice. This correspondence, however, falls on a spectrum. Without knowing the value of a variable like the harmonics-to-noise ratio (HNR), it is not possible to objectively say where on the spectrum a particular item is located with spectral shape alone. HNR thus provides the necessary context for interpreting spectral shape. 

The domain of faces thus provides a useful analogy for thinking about what shared structure looks like compared to idiosyncratic aspects of the structure. \citet{burton_2016_faces} found that all faces share dimensions of variability related to things like lighting and viewing angle (i.e., looking up, down, or to the side). Understanding how a face changes according to light or angle is useful structural knowledge that can be transferred to new faces. It is shared because it applies to all faces. Idiosyncratic variation in face structure arose from things like facial hairstyle, makeup, and expressions. While these variables may be shared by a subset of faces, understanding how something like the application of makeup varies is not applicable to all faces. 

Returning to voice, \citet{lee_2019_acoustic} argue that the structure of voice spaces supports a prototype model of voice perception \citep{lavner_2001_prototype, latinus_2011_voice} in which novel individual voices are perceived in the context of one or more prototypes housed in listeners' memory. \citeauthor{lavner_2001_prototype} define a prototype as a pattern comprising ``an ensemble of acoustic features, related to the language, the accent, the phonemes and allophones, and to the voice production system...[reflecting] the average of speakers’ features or a very common voice'' \citeyearpar[][p. 64]{lavner_2001_prototype}. The authors then argue that new voices are perceived in the context of this prototype, such that ``only those features that significantly deviate from the prototype are stored (memorized) for the long term, and identification of familiar voices is based on searching and locating the voice, using only those features deviating from the prototype'' \citep[][p. 64]{lavner_2001_prototype}.

In any case, \citet{lee_2019_acoustic} argue that familiarity with a voice arises from learning how that voice varies across time and space, whether within an utterance or across environments, physical states, and emotions. This familiarity could easily be characterized in terms of the extent and manner that a voice deviates from a prototype. 

\subsection{Voice perception}

The literature on voice perception has approached the question of what listeners use in voice identification, discrimination, and learning through the lens of familiarity \citep{levi_2019_methodological, perrachione_2018_recognizing}. This body of experimental work pairs different combinations of listeners, talkers, languages, and stimuli manipulations to probe how listeners identify and discriminate among talkers. While identification and discrimination are often talked about in conjunction with one another, the processes are likely supported by different perceptual mechanisms \citep{perrachione_2019_judgments}. One of the key findings from this literature is the Language Familiarity Effect (LFE), which encompasses a broad range of findings where listeners are better at identifying talkers in a familiar language \citep[for a recent review, see][]{perrachione_2018_recognizing}. Bilinguals are especially good at this kind of task and show evidence of generalizing across languages they know \citep{orena_2019_identifying}. 

Very little of this work identifies what listeners use in the signal, and as such, claims about the relative importance of linguistic or talker-indexical information should be tempered. However, there are exceptions to this. For example, \citet{perrachione_2019_judgments} collected perceptual voice (dis)similarity ratings for Mandarin and English voices by Mandarin and English native listeners and reported on the relationship between several acoustic measurements and rating data. \citet{perrachione_2019_judgments} found that when the talker was the same, regardless of the manipulations used in the study (language and time-reversal), all listeners rated stimuli pairs as highly similar. This result highlights that listeners are sensitive to low-level acoustic information present in voices, regardless of whether they know the language or understand the stimuli. Additionally, \citet{perrachione_2019_judgments} found that some acoustic measurements predict similarity ratings, while others do not. F0 was the most prominent measure, which is unsurprising given its salience, and how much the voice variability literature has focused on it---that is, researchers have long considered F0 to be an important variable \cite[e.g.,][]{keating_2012_f0}. Other measures predicting similarity were the harmonics-to-noise ratio and formant dispersion, which are associated with voice quality and vocal tract size, respectively. That listeners appear to use these measures is of direct relevance to the study presented in this chapter, as it signals their importance in perception and processing---this represents a point that will be returned to in this chapter's discussion.

\subsection{Bilingual voices}\label{ch3:sec:clxcomparisons}

In light of this perceptual work on the language familiarity effect and the complicated interactions that abound between different listener and talker populations, it makes sense that \citet{lee_2019_acoustic} restricted variability while introducing a novel set of methods. Their extension to spontaneous English and Seoul Korean demonstrates that this method replicates well and that it also presumably allows for observing typological differences across languages that can affect voice quality. This chapter builds on Lee and colleagues' body of work by extending their methods to the case of spontaneous bilingual speech. 

Describing and analyzing acoustic voice variation in bilingual speech has motivation in both perception and production. As apparent from the language familiarity effect literature, listeners are capable of learning and identifying voices in one language and then generalizing across languages. Listeners are better at identification and discrimination when they have more familiarity with the language, but performance on such tasks tends to be above chance even for listeners who lack familiarity with the language \citep[e.g.,][]{orena_2019_identifying}. Knowledge of the language used in the experiment lends the greatest advantage; however, knowledge of a related language also provides a benefit \citep{zarate_2015_multiple}. Presumably, listeners in the latter situation can extract some degree of linguistic information given overlap in the sound structure of the two languages. In cases where listeners cannot rely on linguistic information, they must be tracking non-linguistic acoustic/auditory information in the voice \citep{perrachione_2019_judgments}. Understanding the structure of that variability brings us one step closer to understanding what listeners are using from the signal to process speech, as it limits the hypothesis space. 

On the production side of things, bilingual speech presents an ideal test case for the argument that voices function like auditory faces. If the structure of variability from each of a bilingual's languages is well matched---comparatively speaking---then voices can be straightforwardly thought of as auditory faces. While ``well-matched'' is a vague term, its use reiterates that the meaningful threshold for comparison is not some absolute value but rather how structure is shared within and across languages for between-talker comparisons. While this characterization may seem unsatisfying, it is worth noting that face variability is not identical across languages. A small body of work illustrates that language identification is possible using only lip movements by both humans \citep{sotofaraco_2007_discriminating} and machines \citep{afouras_2020_now}, indicating that there are indeed language-specific patterns for face perception. An example of this would be the case of languages---like Cantonese and English---with different distributions of lip rounding in their segmental inventories. 

Additionally, examining the structure of the same talker's voice in each language lends additional validation to the arguments made by \citet{lee_2020_language} for the differences between English and Seoul Korean sentence reading. In comparing these studies, Lee and colleagues argue that both language and biological factors contribute to the structure of voice variation. Bilingual speech, again, presents an ideal test ground for disentangling biological and linguistic factors from one another. While common in the literature, the language versus biology dichotomy is somewhat misleading. Voices ultimately have biological constraints due to physical and physiological limitations (e.g., vocal tract length, vocal fold mass) or pathologies. Yet, at the same time, individuals nonetheless exert remarkable and wide-ranging control over their voice space and are highly capable of manipulating factors that are not linguistically important but which signal social and contextual information. This applies across all aspects of an individual's linguistic repertoire \citep{bullock_2009_sociophonetics,wei_2018_translanguaging}. Thus in the case of bilinguals, the only aspect we can be truly confident in being held constant across languages is the biological part. The same ``hardware'' can be used for drastically different ends. 

\subsubsection{English and Cantonese}

In this chapter, I examine how voice varies across a Cantonese-English bilingual's two languages. Some differences are expected, despite the characterization of voices as auditory faces. While all languages have consonants and vowels, they differ in distribution, articulation, and acoustics \citeeg{munson_2010_deconstructing}. An overview of the inventories of Cantonese and English is provided in Tables \ref{ch3:tab:cantoneseinventory} and \ref{ch3:tab:englishinventory}. Additionally, Suprasegmental and prosodic properties also vary. Languages differ in terms of whether a suprasegmental dimension is made use of in distinguishing linguistic contrasts. For example, does a language encode lexical tone contrastively? Another way languages vary in this respect is in how they carve up the suprasegmental linguistic space. For example, how many lexical tones are there? What shapes of tone are present? The question of tone and how it impacts voice variability is relevant in the present case, where the languages considered are Cantonese (a language with lexical tone) and English (a language without lexical tone). Cantonese has six lexical tones, which are often referred to by numbers one through six: (1) high level, (2) high rising, (3) mid level, (4) low falling, (5) low rising, and (6) low level. Segmental and suprasegmental differences both have cascading effects on voice quality. 

\begin{table}[htbp]
    \caption{The Cantonese segmental inventory as described by \citet{matthews_2013_cantonese}. Note that Cantonese vowels combine into many different diphthongs.}
    \label{ch3:tab:cantoneseinventory}
    \centering
    \begin{tabular}{lcccc}
    \toprule
    \textbf{Consonants}  & \textbf{Nasal} & \textbf{Stop/Affricate} & \textbf{Fricative} & \textbf{Approximant} \\
    \midrule
    \textbf{Bilabial}    & m              & p / p\textsuperscript{h}                     &                   &                 \\
    \textbf{Labiodental} &                &                                              & f                 &                 \\
    \textbf{Dental}      & n              & t / t\textsuperscript{h}                     & s                 & l               \\
    \textbf{Alveolar}    &                & ts / ts\textsuperscript{h}                   &                   &                 \\
    \textbf{Velar}       & {\ipafont ŋ}   & k / k\textsuperscript{h}                     &                   &                 \\
    \textbf{Labiovelar}  &                & k\textsuperscript{w} / k\textsuperscript{wh} &                   &                 \\
    \textbf{Glottal}     &                &                                              & h                 &                 \\
                         &                &                                              &                   &                 \\
    \midrule
    \textbf{Vowels}      & \textbf{Front} & \textbf{Central}                             & \textbf{Back}  &                 \\
    \midrule 
    \textbf{High}        & i / y                       &                   & u             & \\
    \textbf{Mid}         & {\ipafont ɛ / œ}            &                   & {\ipafont ɔ } & \\
    \textbf{Low}         &                             & {\ipafont ɐ / aː} &                & \\
    \bottomrule
    \end{tabular}
\end{table}
    
\begin{table}[htbp]
    \caption{The English segmental inventory as described by \citet{wilson_2011_language}, with [{\ipafont ʔ ɾ w̥}] excluded. Note that some English vowels combine into diphthongs.}
    \label{ch3:tab:englishinventory}
    \centering
    \begin{tabular}{lcccc}
    \toprule
    \textbf{Consonants}  & \textbf{Nasal} & \textbf{Stop/Affricate} & \textbf{Fricative} & \textbf{Approximant} \\
    \midrule
    \textbf{Labial}	 	   &  m			   & p / b 		             & f / v 			  & 					 \\
    \textbf{Dental}        & 			   & 				         & {\ipafont θ / ð}	  &						 \\
    \textbf{Alveolar}      &  n 		   & t / d                   & s / z			  & l 				     \\
    \textbf{Palatal}       &			   & {\ipafont tʃ / dʒ}      & {\ipafont ʃ / ʒ}   & {\ipafont ɹ}	     \\
    \textbf{Velar}         &  {\ipafont ŋ} & k / {\ipafont ɡ}        &					  & j					 \\
    \textbf{Glottal}       &               &  				         & h 				  & w            		 \\
                           &               &                         &                   &                      \\
    \midrule
    \textbf{Vowels}      & \textbf{Front}     & \textbf{Central}  & \textbf{Back}        &                      \\
    \midrule 
    \textbf{High}        & i / {\ipafont ɪ}   &                   & u / {\ipafont ʊ}    &                       \\
    \textbf{Mid}         & {\ipafont e / ɛ}   & {\ipafont ə / ʌ } & {\ipafont ɔ }       &                       \\
    \textbf{Low}         & {\ipafont æ}       & 				  & {\ipafont ɑ }       &                       \\
    \bottomrule                
    \end{tabular}
\end{table}

The following paragraphs detail voice quality comparisons that have been made between English and Cantonese in the literature thus far. As there is an additional body of work comparing English and Mandarin Chinese---typologically similar to Cantonese---comparisons between English and Mandarin are also summarized in the next section. While the most relevant comparisons for this chapter are those made within bilinguals, some of the relevant literature compares separate populations. What this body of literature has in common---whether within- or between-talker---is that it paints with relatively broad strokes---crosslinguistic comparisons are often made with summary statistics for a small set of spectral measurements. With such methods, results have been decidedly mixed. 

In a small study of Cantonese-English bilingual (n$=$9), Russian-English bilingual (n$=$9), and English monolingual (n$=$10) young women, \citet{altenberg_2006_f0} examined F0 patterns in conversational speech across the different languages and populations. As some languages reportedly have different mean F0 \citep[e.g.,][]{keating_2012_f0}, \citet{altenberg_2006_f0} focused on whether F0 shifts when an individual switches languages and whether different languages have different baselines. Ultimately, Russian-English bilinguals exhibited differences in mean F0 across their two languages, and Cantonese-English bilinguals did not. Though, they did produce a wider F0 range in Cantonese compared to their English. While the results in \citet{altenberg_2006_f0} ultimately paint a coarse picture of bilingual F0 production with a small sample size, they highlight an important point of departure---bilinguals can differ in F0 across languages. 

In a larger study of Cantonese-English bilinguals reading passages (n$=$40), \citet{ng_2012_ltas} examined a variety of different voice measures with both male and female talkers. Results were based on Long-Term Average Spectral (LTAS) measures. Female talkers exhibited lower F0 in Cantonese than English, but males did not. In the same study, all participants had greater mean spectral energy values (mean amplitude of energy between 0--8 kHz) and lower spectral tilt (ratio of energy between 0--1 kHz and 1--5 kHz) in Cantonese \citep{ng_2012_ltas}. Respectively, these findings suggest a greater degree of laryngeal tension and breathier voice quality in Cantonese compared to English. The LTAS measure of the first spectral peak did not differ across languages, suggesting that vocal stiffness remained consistent in the bilinguals' two languages. 

\citet{ng_2010_voice} examined F0 in spontaneous speech from 86 Cantonese-English bilingual children and found it to be lower in Cantonese compared to English. This corroborates \citet{ng_2012_ltas}, and goes against the nonsignificant difference in \citet{altenberg_2006_f0}. This mixed bag of results could ultimately be attributed to differences in sample sizes, the quantity of speech analyzed, or the language backgrounds of the bilinguals studied. While the picture regarding voice quality measures appears clearer and more consistent, those conclusions arise from a single study. In any case, these three studies offer reason to expect that Cantonese and English might differ in measures associated with pitch and phonation type. 

\subsubsection{English and other languages}

The authors of these studies speculate that Cantonese's status as a tone language may account for some of these differences compared to English. It is important to emphasize that this explanation is pure speculation. In this light, it is also relevant to consider the larger body of research comparing voice quality for Mandarin and English. \citet{lee_2017_bilingual} compare F0, speech rate, and intensity in a small group of Mandarin-English bilinguals (n$=$11) across three different tasks. They report a higher mean F0 for Mandarin reading compared to English, but no differences in the other tasks (picture description and monologue). Additionally, there were no differences in F0 variability across languages or tasks. Lastly, while there were no differences in intensity, the bilinguals spoke faster in Mandarin. \citet{lee_2017_bilingual} speculate that Mandarin's status as a tone language may account for the higher mean F0 in reading, as it echoes some prior work with separate populations of English and Mandarin speakers, in which Mandarin tends to have higher and more variable F0 \citep{keating_2012_f0}. This finding may be strongly associated with the type of bilinguals studied. \citet{xue_2002_f0} found that Mandarin-English bilinguals aged 22-35 produced lower F0 in Mandarin than English. This group differed from the participants in \citet{lee_2017_bilingual}, in that they are described as non-native English speakers. Producing higher F0 in a non-native language arguably reflects factors like stress or confidence \citep{jarvinen_2013_speaking, lee_2017_bilingual}.

The speculation that higher F0 is a feature of tone languages does not align with the observation in \citet{ng_2012_ltas}, who argued the opposite for Cantonese: that lower F0 could be accounted for by lexical tone. While the tone inventories for Cantonese and Mandarin have substantial differences, it seems clear that a simple appeal to the presence or absence of lexical tone does not present a substantive argument. While an account that invokes the distribution of lexical tones would be somewhat more compelling, it would also need to account for all of the other ways that F0 varies in language production (e.g., prodosy). Alternatively, talkers may be expressing different social and cultural identities in each of their languages \citep{loveday_1981_pitch, voigt_2016_between}. Regardless of whether language, experiential, or social factors drive differences across languages, this body of work highlights the importance of comparing within the same task (i.e., isolated word production, reading, spontaneous speech, etc.). 

Treating Mandarin and Cantonese as similar just because they are both tone languages may not be appropriate, though there is little in the way of conclusive research on the topic. In a study with 12 Cantonese-Mandarin bilinguals who are Cantonese-dominant, \citet{yang_2020_f0} found no differences in their F0 profiles across languages. F0 profiles were characterized by F0 minimum, maximum, range, and mean. The authors also examined a Mandarin-dominant group and reported clear differences between the two populations' F0 profiles in Mandarin. The Mandarin-dominant individuals produced higher F0 with a narrower range. While the conclusions from this study are tenuous given the small sample size, it nonetheless highlights an important point: that typologically related tone languages may not necessarily behave comparably.

While the studies reviewed thus far provide a mixed picture of voice differences across language pairs, there is a strong focus on F0. Both the F0-centricity and variable outcomes are apparent in work on other language pairs as well. For example, \citet{cheng_2020_f0} finds that Korean has consistently higher F0 than English, regardless of whether they were early sequential or simultaneous bilinguals, and that differences in F0 range differed for cisgender males and females. This result builds on the findings for Korean-English bilinguals \citep{lee_2017_bilingual}. While the results for Korean-English bilinguals seem to be straightforward, the same cannot be said for other language pairs. For example, \citet{ryabov_2016_self} look at rate, duration, and F0 for Russian-English bilinguals, finding no F0 differences, but that Russian was faster. This result goes against the findings for the bilinguals studied in \citet{altenberg_2006_f0}, where Russian exhibited consistently higher F0 than English. While higher F0 and slower speech rates can be characteristics of speech by non-native or non-dominant speakers \citep{jarvinen_2013_speaking}, such an explanation cannot account for both outcomes.

Another example of less than clear-cut results comes from \citet{ordin_2017_cross}---they demonstrate differences in F0 range and level across languages for female Welsh-English bilinguals in a reading task, for whom Welsh had a higher and wider F0 range. This result did not hold for males from the same population, who varied more in their F0 level and range. The authors argue that the crosslinguistic difference is likely to be sociocultural in this case, as different patterns were observed for male and female speakers on a within-speaker basis. \citet{ordin_2017_cross} argue that if a difference in F0 stemmed purely from language differences, that males and females would both show the pattern. Because this is not the case, they argue that the result is unlikely to be due to anatomical or purely linguistic reasons. While this argument does not necessarily disentangle social from linguistic, it emphasizes the need to consider social dimensions. 

Considering these studies together, a few key observations are especially relevant to the present chapter. While studying bilingual talkers provides a clear path to disambiguating the role of anatomical differences in voices, it does not necessarily facilitate disentangling linguistic and sociocultural factors from one another. Most likely, both contribute simultaneously to the differences in voice patterns across languages---and may or may not be disentangle-able. For example, there is clear evidence that Korean has a higher F0 than English, given results from two studies with different populations of bilinguals \cite{cheng_2020_f0, lee_2017_bilingual}. On the other hand, \citet{ordin_2017_cross} show social rather than linguistic stratification via gendered patterns in Welsh-English bilinguals. While these studies examine different populations, they nonetheless highlight different sources of variation.

This body of work mostly focuses on linguistic and social differences. While some of it dives into individual differences, between-talker variability should perhaps be given more of a spotlight. In work with speech rate, \citet{bradlow_2017_rate} found that some talkers are fast and others are slow and that some languages are fast while others are slower. Crucially, these relationships held across talkers in various languages. That is, if someone was a fast talker in their dominant language, they were also a fast talker in their non-dominant language, and likewise for slow talkers. In this sense, both talker-indexical and linguistic (or sociocultural) factors contribute to speech rate behavior. It is not a particularly big leap to suggest that other speech signal variables might pattern in the same way. Adding to this picture of variability across individuals, it is important to remember that bilinguals are sophisticated social actors and are fully capable of tailoring their speech behavior to a wide variety of contexts \citep{bullock_2009_sociophonetics}. 

\subsection{The present study}

While this body of work highlights important points, it is limited by its laser focus on F0, with occasional forays into speech rate, intensity, and other spectral measures. The focus on F0 is not without reason---\citet{perrachione_2019_judgments} found it to be the most important perceptual dimension for voice similarity ratings. Yet, at the same time, there is so much more to voice than pitch, particularly if the characterization of voices as auditory faces holds up. 

This chapter brings together work describing crosslinguistic voice differences and work describing the structure of acoustic voice variation to provide a more comprehensive picture of how voices vary across languages. Using the corpus introduced in \ref{ch2:corpus}, I describe various spectral properties \citep[e.g.][]{ng_2012_ltas}, and also examine how acoustic variation is structured, following the work of Kreiman, Lee, and colleagues \citep{kreiman_2014_theory,lee_2019_acoustic}. This chapter builds on \citet{lee_2019_acoustic} in a handful of ways: it extends the methods to the case of bilinguals, considers longer samples, and addresses the role of sample duration both within and across talkers and languages. I also extend their methods by introducing a mechanism to assess structural similarity within and between individuals and languages. 

\section{Methods \& Results}\label{ch3:sec:methods_results}

\subsection{Data}\label{ch3:sec:data}

The data used in this analysis comes from the conversational interviews in the SpiCE corpus described in Chapter \ref{ch2:corpus}. The analysis uses both Cantonese and English interviews. As noted before, the 34 talkers studied here are all early Cantonese-English bilinguals from a heterogeneous speech community \citep{liang_2015_china}. For additional information about the participants, please refer to sections \ref{ch2:subsec:participants} and \ref{ch2:sec:statistics} in the previous chapter. 

While prior work by Lee and colleagues \citep[e.g.,][]{lee_2019_acoustic} uses relatively short chunks of speech, the present analysis is focused on longer stretches of spontaneous speech from conversational interviews. While it would have been possible to include the sentence reading and storyboard task recordings from each participant, there are practical reasons for excluding them from the analysis. The sentence sets were overall quite short and thus unlikely to be sufficiently representative on their own. Additionally, as many of the SpiCE talkers were not confident in their Cantonese reading, there was a wide range of familiarity with the materials represented. Some talkers knew all of the sentences, and others struggled with some of them. This variability renders the sentences less comparable to their English counterparts in the SpiCE corpus. There are also imbalances in the storyboard task. As talkers narrated the same story in both languages, they were often more confident the second time around. Excluding both of these tasks is motivated by prior work that highlights how confidence \citep{jarvinen_2013_speaking} and speaking style \citep{lee_2017_bilingual} impact voice quality. 

As discussed in the previous chapter, the recordings are high-quality, with a 44.1 kHz sampling rate, 16-bit resolution, and minimal background noise. Recall that both the participant and interviewer wore head-mounted microphones connected to separate channels, and levels were adjusted to minimize speech from the other talker. For the analysis in this chapter, the participant channel was extracted from the stereo recordings, including any code-switches they made during the interview. While it would be possible to exclude items not produced in the primary language of the interview, this was not done. The driving reason for keeping code-switches in the analysis is that such code-switches are representative of the particular talker's language behavior. Further, just because someone switches languages does not mean that they fully and immediately switch language modes \citep[e.g.,][]{fricke_2016_phonetic}. For example, individual words may be borrowed and pronounced with the phonology of the interview's primary language \citep[cf. the matrix language in code-switching][]{myersscotton_2011_matrix}. 

All voiced segments were identified with the \textit{Point Process (periodic, cc)} and \textit{To TextGrid (vuv)} Praat algorithms \citep{boersma_2021_praat}, implemented with the Parselmouth Python package \citep{jadoul_2018_parselmouth}. The pitch range settings used with \textit{Point Process (periodic, cc)} were 100--500 Hz for female talkers and 75--300 for male talkers. These settings reflect a balance between known differences between male and female pitch \citep{simpson_2009_phonetic} and the wide range of F0 variability in spontaneous speech while guarding against the pitch estimation issues of doubling and halving. While speech from the interviewer can occasionally be heard in the participant channel, it is quiet enough to have been ignored by the Praat algorithms and likely did not influence the results.\footnote{Note, however, that the volume of the interviewer's speech was not examined in either channel of the stereo recordings.} This method of identifying voiced portions of the speech signal captures vowels, approximants, and some voiced obstruents. As a result, this process differs slightly from the methods described in \citet{lee_2019_acoustic}, the paper on which the methods of this chapter were modeled. \citet{lee_2019_acoustic} examined only vowels and approximants. 

\subsection{Acoustic measurements}\label{ch3:sec:acoustic}

All voiced segments were subjected to the same set of acoustic measurements of voice quality made by \citet{lee_2019_acoustic}, except formant dispersion, which was excluded given its very strong correlation with the measured value of F4 in this chapter (following the exclusionary criteria in Section \ref{ch3:sec:exclusions}: Pearson's \textit{r} $=$ 0.94, df $=$ 3071734, p $<$ 0.001). The choice of measurements in \citet{lee_2019_acoustic} is based on the psychoacoustic voice quality model described in the introduction to this chapter \citep{kreiman_2014_theory}, as well as the availability of algorithms in the software used to extract measurements. Measurements were made every 5 ms during voiced segments in VoiceSauce \hl{Version 1.28?} \citep{shue_2011_voicesauce}. The measurements are described below. Note that the shorthand name for each measurement is presented in boldface and will be used throughout the rest of the chapter. 

\begin{description}
    \item[F0] Fundamental frequency is a correlate of pitch and is associated with linguistic (e.g., lexical tone), prosodic, and talker characteristics. F0 was measured in Hertz using the STRAIGHT algorithm \citep{kawahara_2016_straight}. It is one of the more widely studied variables on this list, as evidenced by the literature cited in the introduction.
    \item[F1, F2, and F3] The first three formant frequencies---also measured in Hertz---are typically discussed for linguistic contrasts, particularly with vowels and sonorant consonants. Recall the differences in Cantonese and English inventories described in Tables \ref{ch3:tab:cantoneseinventory} and \ref{ch3:tab:englishinventory}. All formants were estimated using the Snack Sound Toolkit method \cite{sjolander_2004_snack}, with the default settings of 0.96 pre-emphasis, 25 ms window length, and 1 ms frameshift.
    \item[F4] The fourth formant frequency is not typically discussed in linguistic contexts and is instead associated with talker characteristics, such as vocal tract length. In this light, it is not particularly surprising that it was highly correlated with formant dispersion. F4 is also measured in Hertz. It was calculated along with the first three formants using the same settings.
    \item[H1*--H2*] The corrected amplitude difference between the first two harmonics is one of four primary measures used to characterize source spectral shape---also called spectral tilt---in the psychoacoustic model of voice quality \citep{kreiman_2014_theory}. It is typically associated with phonation type, such that lower values fall on the creakier end of the spectrum and higher values on the breathier end of the spectrum \citep{garellek_2019_voice}. Interpretation is less than straightforward, however, as determining where on the spectrum from creaky to breathy a particular observation falls depends on a measure of spectral noise \citep[e.g., CPP below;][]{garellek_2019_voice}. Additionally, H1*--H2* can be confounded by nasality \citep{munson_2019_phonetics}. The asterisks here---and in the following spectral shape measures---indicate that the value has been corrected \citep{iseli_2007_voice}, to account for the amplifying impact of nearby formants on the amplitudes of harmonics. This allows for different vowels and other voiced segments to be compared with one another. This amplitude difference is measured in dB. Note that this measure---along with the following three spectral shape measures---depends on an accurate F0 measurement.
    \item[H2*--H4*] The corrected amplitude difference between the second and fourth harmonics is the second of four measures capturing spectral shape. Like H1*--H2*, it is associated with phonation type and is measured in dB.
    \item[H4*--H2kHz*] The corrected amplitude difference between the fourth harmonic and the harmonic closest to 2000 Hz is the third spectral shape measure. Unlike the previous two, one of the harmonics depends on F0, while the other does not. It captures shape in a higher frequency range and is also associated with phonation in a similar manner to H1*--H2*. Like the other spectral shape measures, it is in dB.
    \item[H2kHz*--H5kHz] The amplitude difference between the harmonics closest to 2000 Hz (corrected) and 5000 Hz (uncorrected) is a measure of harmonic spectral shape that does not depend on F0. The amplitude of the harmonic nearest 5000 Hz is not corrected by VoiceSauce, given inaccuracies in the correction algorithm at higher frequencies. It captures the highest frequency band of the four shape measures, reflects phonation type as H1*--H2* does, and is measured in dB.
    \item[CPP] Cepstral Peak Prominence measures the degree of harmonic regularity in voicing, and as such, it is associated with non-modal phonation types. VoiceSauce computes CPP according to the algorithm in \citet{hillenbrand_1994_acoustic}. Specifically, CPP measures the difference between the amplitude of the peak in a cepstrum and the value at the same quefrency on the regression line for that cepstrum. It is measured in dB.\footnote{For details and definitions of terms like \textit{cepstrum} and \textit{quefrency}, please refer to \citet{hillenbrand_1994_acoustic}.}
    \item[Energy] Root Mean Square (RMS) Energy is a measure of spectral noise that reflects overall amplitude and is calculated over a window comprising five pitch periods. Energy is measured in dB.
    \item[SHR] The subharmonics-harmonics amplitude ratio is a measure of spectral noise associated with period-doubling or irregularities in phonation. VoiceSauce's implementation is based on the algorithm described in \cite{sun_2002_shr}. While based on amplitude, this ratio is unitless. 
\end{description}

The raw VoiceSauce output used in this chapter is available in a repository on the Open Science Framework, in the data subfolder at \url{https://osf.io/9ptk4/}. The analysis code used for the following sections is available on GitHub, at \url{https://github.com/khiajohnson/dissertation}.\footnote{Note that this repository is currently private.}

\subsection{Exclusionary criteria and post-processing}\label{ch3:sec:exclusions}

Given the nature of the corpus and the level of automation in the methods thus far, there is reason to expect a sizable number of erroneous measurements. To filter these out before analysis, measurements were subjected to exclusionary criteria focused on identifying impossible values. Observations were excluded in cases where any of the following measurements had a value of zero: F0, F1, F2, F3, F4, CPP, or uncorrected H5kHz. Observations were also excluded if Energy was more than three standard deviations above the grand mean. This may exclude some valid measurements but removes the long right tail of likely erroneous measures, as humans can only produce speech so loud. 

Filtering based on F0 and the four formant frequencies reflects the observation that zero measurements are not possible for voiced portions of the speech signal. The interpretation for zero in CPP would indicate there is no cepstral peak, that is, no regularity in the voicing. As nonzero values for CPP reflect a range of modal and nonmodal phonation, a zero for CPP likely reflects either a lack of voicing or an erroneous F0 measurement. Lastly, only the uncorrected spectral measure for H5kHz was used in filtering (not the difference used in the analysis), as erroneous values tended to co-occur on the same observation. The distribution of H5kHz did not span zero, except for a spike of erroneous values equal to zero. This operationalization minimizes the removal of correctly measured zero values, which occurred with all of the other spectral shape parameters, whether corrected or uncorrected. In aggregate, these filtering criteria led to the removal of 37\% of the original set of observations.

Moving standard deviations were calculated for each of the 12 measures using a centered 50 ms window, such that each window includes approximately ten observations. The moving standard deviations capture dynamic changes for each of the voice quality measures, which is important, as they may better reflect what listeners attend to in talker identification and discrimination tasks \citep{lee_2019_acoustic}. This analysis uses moving standard deviations, as opposed to the coefficients of variation used by \citet{lee_2019_acoustic}. The rationale for this difference is that all variables were scaled before inclusion in the principal components analyses described in the next section, and as a result, there should not be any undue effect on the outcome as the transformation from standard deviation to coefficient of variation is a scaling transformation. The last round of exclusionary criteria uses these moving standard deviations. If an observation was missing a moving standard deviation value, it was removed. Given the centered window, this means that observations falling less than 25 ms away from a voicing boundary were not included. 

There were 24 total measures, with a measured value and a moving standard deviation for each of the acoustic measurements listed above. These 24 measures were used in the analyses described in the following sections. Across the 34 talkers, there were 3,071,736 observations after winnowing the data from an initial count of 6,560,403 observations. These observations were not evenly distributed across talkers and languages. While this full set of observations is perfectly valid for the crosslinguistic comparison in Section \ref{ch3:sec:comparison} and is used there, sample size may have an impact on the principal components based analysis in Sections \ref{ch3:sec:pca} and \ref{ch3:sec:cca}---this is expanded upon in the next paragraph.

To control for the impact of sample size in that part of the analysis, the number of samples for each talker was capped to include only the first 20,124 samples for each interview. This value was selected as it represents the interview with the fewest observations. Put simply, differences in sample size reflect the variability in how much different individuals in the corpus talked. Those who produced longer passages of speech ultimately had more observations of voiced speech. Passage length was expected to impact the analysis, given how much affect and style can vary within a single conversation. Over time, individuals cover more of their range of variation, and as such, a regression to the mean is expected over time. That is, PCAs based on shorter stretches of speech would be subject to greater variability, while those based on longer stretches would converge on a structure. To level the playing field in this first analysis, the sample size was controlled. At the end of this chapter, in Section \ref{ch3:sec:passagelength}, a follow-up analysis validates this assumption. To preview those results, 20,000 samples appear sufficient for capturing the range of variability in acoustic voice variation.

Following this last winnowing step, there were 1,368,432 total observations (34 talkers $\times$ 2 interviews $\times$ 20,124 observations per interview). While the winnowing process removed a substantial amount of the data, the total number of samples per talker is still much larger than the approximate 5,000 used in \citet{lee_2019_acoustic}. 

\subsection{Crosslinguistic comparison of acoustic measurements}\label{ch3:sec:comparison}

Following prior work, the first step in this analysis is a crosslinguistic comparison for each talker and measure. As discussed in the introduction to this chapter, there are some commonly found---though inconsistent---differences between Cantonese and English. Prior work has found that speakers sometimes produce lower and more variable F0 in Cantonese \citep{altenberg_2006_f0,ng_2012_ltas,ng_2010_voice}. Additionally, \citet{ng_2012_ltas} also report on spectral measurements that indicate Cantonese has a generally more breathy (or less creaky) phonation quality compared to English. Other measures were either inconclusive, non-significant, or not considered by the researchers. Figure \ref{ch3:fig:allmeasures} depicts the distribution of values for each of the acoustic measurements across languages, with all talkers pooled together. 

\begin{figure}[htbp]
    \begin{center}
    \includegraphics[width=0.9\linewidth]{figures/ch3_allmeasuresdensity_5in.png} 
    \caption{Each panel depicts a density plot that pools measurments from all talkers together to show the range of values for that measure. The x-axes each have their own scale. Language is separated out by color.}
    \label{ch3:fig:allmeasures}
    \end{center}
\end{figure} 

For each acoustic measurement and talker, Cohen's \textit{d} was calculated using the \textit{lsr} package \citep{navarro_2015_lsr} in R \citep{r_2021}; this provides a high-level assessment of whether variable means differed across the two languages. These comparisons have no bearing on how a given variable \textit{varies}. Table~\ref{ch3:tab:cohend} reports counts of talkers by effect size. Notably, across all talkers and variables, only 21.1\% yielded non-trivial Cohen's \textit{d} values, though most talkers (32/34) had at least one non-trivial comparison. The distribution of these counts is depicted in Figure~\ref{ch3:fig:ntcounts}. Additionally, Figures \ref{ch3:fig:cohendmeasure} and \ref{ch3:fig:cohendsd} depict the relationship between the difference of means across languages and Cohen's \textit{d} for all of the measures. While redundant, these figures facilitate visual identification of the trends in the data.
 
\begin{table}[htbp]
\caption{This table reports counts of Cohen's \textit{d} for crosslinguistic comparisons of each of the acoustic measurements by talker. For most talkers and variables, the difference in means was trivial, which is reflected in that column's high counts.}
\label{ch3:tab:cohend}
\centering
\begin{tabular}{lccc}
\toprule
         & \multicolumn{3}{c}{\textbf{Cohen's \textit{d}}} \\
         & \textbf{Trivial} & \textbf{Small} & \textbf{Medium} \\
\textbf{Variable} & \textbf{\textit{0.0--0.2}} & \textbf{\textit{0.2--0.5}} & \textbf{\textit{0.5--0.8}} \\ 
\midrule
F0	        &	21	&	10	&	3	\\
F0 s.d.	    &	34	&	-	&	-	\\
F1	        &	24	&	9	&	1	\\
F1 s.d.	    &	29	&	5	&	-	\\
F2	        &	26	&	8	&	-	\\
F2 s.d.	    &	32	&	2	&	-	\\
F3	        &	24	&	9	&	1	\\
F3 s.d.	    &	29	&	5	&	-	\\
F4	        &	30	&	3	&	1	\\
F4 s.d.	    &	28	&	6	&	-	\\
H1*--H2*	    &	18	&	15	&	1	\\
H1*--H2* s.d.	&	32	&	2	&	-	\\
H2*--H4*	    &	25	&	9	&	-	\\
H2*--H4* s.d.	&	31	&	3	&	-	\\
H4*--H2kHz* 	    &	25	&	8	&	1	\\
H4*--H2kHz*  s.d.	&	34	&	-	&	-	\\
H2kHz*--H5kHz	    &	23	&	10	&	1	\\
H2kHz*--H5kHz s.d.	&	31	&	3	&	-	\\
CPP	        &	21	&	10	&	3	\\
CPP s.d.	&	32	&	2	&	-	\\
Energy	    &	17	&	14	&	3	\\
Energy s.d.	&	18	&	16	&	-	\\
SHR	        &	31	&	3	&	-	\\
SHR s.d.	&	29	&	5	&	- \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
    \begin{center}
    \includegraphics[width=0.875\linewidth]{figures/ch3_nontrivial_counts_by_talker_5in.png} 
    \caption{A histogram summary of the number of non-trivial comparisons from Table~\ref{ch3:tab:cohend} across the 34 talkers.}
    \label{ch3:fig:ntcounts}
    \end{center}
\end{figure}

\begin{figure}[htbp] 
    \begin{center}
    \includegraphics[width=0.9\linewidth]{figures/ch3_cohend_part1_5in.png} 
    \caption{Each panel plots Cohen's \textit{d} on the x-axis (scales differ) and the difference between language means on the y-axis. Positive values indicate a higher mean in Cantonese than English. The color reflects the levels of interpreation for Cohen's \textit{d}. Each point represents a talker.}
    \label{ch3:fig:cohendmeasure}
    \end{center}
\end{figure}

\begin{figure}[htbp]
    \begin{center}
    \includegraphics[width=0.9\linewidth]{figures/ch3_cohend_part2_5in.png} 
    \caption{This figure uses the format of \ref{ch3:fig:cohendmeasure}, but reports on the standard deviation measures.}
    \label{ch3:fig:cohendsd}
    \end{center}
\end{figure}

For the non-trivial comparisons, there were consistent patterns across languages for a handful of the variables, including F0, H4*--H2kHz, and to a lesser extent, H1*--H2**. If there was a non-trivial difference in F0 across languages, then Cantonese had a lower mean F0 than English (13/34; Female = 7), though most talkers did not exhibit a difference (21/34). This is consistent with prior findings that when a difference between English and Cantonese was found, Cantonese had a lower mean F0 for females \citep{ng_2012_ltas,altenberg_2006_f0}. I also observe this difference at similar rates for female and male talkers.

As for the two spectral shape measures, H4*--H2kHz was consistently lower in Cantonese when the comparison was not trivial (n=9), though most talkers did not exhibit a difference on this measure. H1*--H2* was significantly higher in Cantonese for a relatively large subset of the talkers (13/34), lower for a small number (3/34), but trivial for most (18/34). While based on different measures than \citep{ng_2012_ltas}, the H1*--H2* results are consistent with the finding that Cantonese tends to be breathier (or English creakier)---the current analysis does not distinguish between these interpretations. The H4*--H2kHz results are not consistent with \citet{ng_2012_ltas}, yet for both spectral shape measures, it is important to reiterate that they are difficult to interpret on their own. The interpretation here should be taken with a grain of salt. 

For the remaining variables, while some talkers exhibited a difference in mean values, the direction of the difference varied, or relatively few talkers exhibited the difference. For example, a variable like F4 would be unlikely to vary across languages, given its association with vocal tract size. This interpretation is reflected in the relatively low count of talkers with a non-trivial difference across languages for F4. 

Another example of variable behavior comes from F2, which also stands out because of the stark difference in Figure \ref{ch3:fig:allmeasures}. While the distribution is perhaps not surprising, given the extent to which English high and mid back vowels have fronted across numerous varieties of English, including those in Western North America \citep{labov_2008_atlas}, the figure seems to be at odds with the Cohen's \textit{d} results in Table \ref{ch3:tab:cohend}---of eight non-trivial comparisons, two were positive and six were negative. The difference in the figure, however, seems to be driven by individual differences in F2 behavior, as the stark difference is not reflected on an individual level. Instead, talkers tend to have either a wide spread of F2 values or a strongly skewed distribution with a long right tail in both languages---this indicates that vowel fronting varies by individual. 

Other measures, such as Energy, have numerous non-trivial comparisons but show a relatively even split for direction (Positive = 7, Negative = 10). The large spread for Energy may reflect things like speaking confidence in the two languages, which likely varies by individual \citep{jarvinen_2013_speaking}.

CPP also exhibits a split between positive (n=6) and negative (7). Higher CPP values are associated with both breathy or creaky non-modal phonation types. In this sense, a positive difference would indicate that Cantonese was more non-modal, while a negative difference would indicate that English was more non-modal. Interpreting CPP is not so straightforward, however, as it is not immediately clear which type of non-modal phonation the measure entails. Given the H1*--H2* results, it seems clear that knowing where on the creaky-modal-breathy spectrum a given speaker falls is pertinent to interpreting this measure. CPP would likely corroborate that outcome on a by-observation basis. In any case, listener assessments would help pinpoint how spectral shape and noise parameters map onto voice quality.  

Overall, while talkers show some clear across-language differences, these are far outnumbered by instances with no difference. The variability observed here fits in with the variable outcomes of previous work. Yet, at the same time, the results in this section do not neatly compare to clearcut differences between male and female talkers found in prior work.

\subsection{Principal components analysis}\label{ch3:sec:pca}

\subsubsection{Methods}

Principal components analysis (PCA) is a dimensionality reduction technique appropriate for data with many potentially correlated variables. In the case of voices, distilling numerous acoustic dimensions into a smaller number of components facilitates identifying and describing the structure of voice variability. PCA provides insight into how variables pattern together in a data set. This feature of PCA is especially relevant here, as voice perception research has made it clear that individual acoustic measurements may be necessary to capture and encode a voice but may not be perceptually meaningful to listeners. What matters is how the different pieces conspire together and ultimately form a percept---though, the PCA itself does not shed light on perception. Rather, it offers a signal-based account that can be used to generate perception prediction and interpret the results of perception research, as outlined in Chapter \ref{ch1:intro}.

Often, the goal of PCA is to take a large number of dimensions and extract a much smaller set to use for some additional purpose (e.g., linear regression). The focus in this chapter is on the internal structure of the components. That is, I examine what makes up components for different talkers and whether an individual's voice structure varies (or not) across languages. 

I adapt methods from work on voices \citep{lee_2019_acoustic, lee_2020_language} and faces \citep{burton_2016_faces, turk_1991_eigenfaces}. The goal of this analysis is to capture similarities or differences in the structure of each talker's voice across languages. As such, I conducted 68 PCAs---one for each talker and language combination---and compared the results of each talker's English and Cantonese PCAs. All 24 measures were standardized on a by-PCA basis before the analysis. PCAs were implemented with the \textit{parameters} package \citep{ludecke_2020_parameters} in R \citep{r_2021}, using an oblique \textit{promax} rotation to simplify the factor structure, as the measurements reported in the previous section were expected to be somewhat correlated given prior findings \citep{lee_2019_acoustic} and a broader understanding of how different acoustic measures align with one another \citep{kreiman_2014_theory, kreiman_2021_validating}.

A crucial step in a PCA is determining the number of components. As PCA is a dimensionality reduction technique, this number is crucially smaller than the total number of components. There are many different methods for setting the number, and in this analysis, each PCA included the number of components for which all resulting eigenvalues were greater than 0.7 times the mean eigenvalue, following \citeauthor{jolliffe_2002_pca}'s \citeyearpar{jolliffe_2002_pca} recommended adjustment to the Kaiser-Guttman rule. This rule was used in place of a more sophisticated test (e.g., broken sticks), as it is not detrimental to this exploratory analysis to err on the side of including marginal components (i.e., those that account for relatively minimal amounts of the overall variance). 

Additionally, across each of the components, only loadings with an absolute value of 0.45 or higher were interpreted \citep{lee_2019_acoustic, tabachnick_2013_statistics}. While \citet{lee_2019_acoustic} use a threshold of 0.32, \citet{tabachnick_2013_statistics} note that higher loadings indicate that a particular variable is a better measure of the component, with 0.32 corresponding to poor (but still interpretable) overlap between the variable and the component. The guidelines in \citet{tabachnick_2013_statistics} indicate that loadings of 0.45 correspond to fair, 0.55 to good, 0.63 to very good, and 0.71 and above to excellent. Given the large number of components and loadings in this analysis, only loadings greater than the fair threshold are interpreted. This methodological decision facilitates interpreting meaningful loadings on components. 

% revised up to here

\subsubsection{Results}\label{ch3:sec:pca_results} 

The PCAs across both languages for all 34 talkers resulted in 10--14 components and accounted for 74.9--82.7\% of the total variation. Half of the talkers had the same number of components for each language (17 of 34). Of the remainder, 16 of the 34 talkers had a difference of one in the number components, and only one had a difference of two. Talkers had 4--11 identical component configurations across their languages (M$=$7.82). These shared components represent 33.3\%--91.7\% of the total components for talkers (M$=$66.7\%). The numbers comprising these summary statistics are provided in Table \ref{ch3:tab:componentcount}. While this already indicates a substantial amount of shared lower-dimensional structure across languages, it likely underestimates the actual shared structure. The reason is that similarity of component structure is not taken into account (i.e., a component of F2, F3, and F4 versus a component with just F2 and F3), as is the case in Section \ref{ch3:sec:cca}. 

\begin{table}[htbp]
    \caption{The number of componentsm variance accounted for, and number of identical components across languages for each PCA.}
\label{ch3:tab:componentcount}
\centering
{\footnotesize 
    \begin{tabular}{llllll}
    
    \toprule
     & \multicolumn{2}{l}{\textbf{Cantonese}} & \multicolumn{2}{l}{\textbf{English}} &  \\
    \textbf{Talker} & \textbf{N} & \textbf{Variance} & \textbf{N} & \textbf{Variance} & \textbf{Identical N} \\
    \midrule
    \textbf{VF19A} & 11 & 0.77 & 12 & 0.80 & 8 \\
    \textbf{VF19B} & 12 & 0.78 & 12 & 0.78 & 8 \\
    \textbf{VF19C} & 12 & 0.78 & 12 & 0.79 & 9 \\
    \textbf{VF19D} & 13 & 0.81 & 13 & 0.78 & 9 \\
    \textbf{VF20A} & 11 & 0.78 & 12 & 0.79 & 6 \\
    \textbf{VF20B} & 13 & 0.81 & 12 & 0.82 & 8 \\
    \textbf{VF21A} & 12 & 0.78 & 12 & 0.80 & 6 \\
    \textbf{VF21B} & 12 & 0.78 & 12 & 0.80 & 8 \\
    \textbf{VF21C} & 14 & 0.83 & 13 & 0.83 & 10 \\
    \textbf{VF21D} & 12 & 0.79 & 12 & 0.81 & 9 \\
    \textbf{VF22A} & 11 & 0.78 & 12 & 0.80 & 7 \\
    \textbf{VF23B} & 12 & 0.78 & 12 & 0.78 & 8 \\
    \textbf{VF23C} & 12 & 0.79 & 12 & 0.80 & 7 \\
    \textbf{VF26A} & 12 & 0.78 & 13 & 0.80 & 7 \\
    \textbf{VF27A} & 11 & 0.79 & 11 & 0.77 & 8 \\
    \textbf{VF32A} & 12 & 0.78 & 11 & 0.76 & 8 \\
    \textbf{VF33B} & 12 & 0.77 & 12 & 0.79 & 9 \\
    \textbf{VM19A} & 12 & 0.78 & 11 & 0.76 & 5 \\
    \textbf{VM19B} & 11 & 0.80 & 12 & 0.80 & 6 \\
    \textbf{VM19C} & 11 & 0.76 & 11 & 0.78 & 6 \\
    \textbf{VM19D} & 13 & 0.80 & 14 & 0.82 & 10 \\
    \textbf{VM20B} & 12 & 0.80 & 11 & 0.76 & 9 \\
    \textbf{VM21A} & 10 & 0.78 & 11 & 0.79 & 5 \\
    \textbf{VM21B} & 11 & 0.79 & 11 & 0.76 & 9 \\
    \textbf{VM21C} & 12 & 0.80 & 12 & 0.77 & 9 \\
    \textbf{VM21D} & 11 & 0.75 & 12 & 0.77 & 7 \\
    \textbf{VM21E} & 10 & 0.74 & 12 & 0.80 & 7 \\
    \textbf{VM22A} & 12 & 0.77 & 13 & 0.83 & 11 \\
    \textbf{VM22B} & 12 & 0.79 & 12 & 0.79 & 7 \\
    \textbf{VM23A} & 12 & 0.81 & 12 & 0.79 & 4 \\
    \textbf{VM24A} & 11 & 0.77 & 11 & 0.76 & 8 \\
    \textbf{VM25A} & 12 & 0.81 & 12 & 0.77 & 11 \\
    \textbf{VM25B} & 11 & 0.74 & 12 & 0.76 & 7 \\
    \textbf{VM34A} & 11 & 0.77 & 12 & 0.81 & 10 \\
    \bottomrule
    \end{tabular}
}
\end{table}

To assess whether talkers exhibit the same structure in voice variability across their languages, I first consider the patterns present across the different PCAs. This provides context for understating what unique structural characteristics in talkers' voices looks like. To this end, I briefly summarize common patterns across PCA components, regardless of how much variance they account for, as the difference is often quite small. Figure~\ref{ch3:fig:VF32A} shows all of the components of participant VF32A's Cantonese and English PCAs, illustrating some examples of how components can vary (or not) across languages. It also highlights the importance of not attributing too much value to the ordering of components, but rather to their composition and variance accounted for.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.8\linewidth]{figures/ch3_pca_vf32a_vert5in.png} 
\caption{In this depiction of the components of VF32A's Cantonese and English PCAs, loadings are represented by bar height and are labelled with the variable name; color represents conceptual groupings; and, the component's variance is superimposed.}
\label{ch3:fig:VF32A}
\end{center}
\end{figure}

Broadly, there were many similarities in component composition across talkers and languages. The following paragraphs summarize the components that were present in every PCA, regardless of talker or language. The shared component accounting for the most variation across talkers had a core structure consisting of F2 and H4*-H2kHz*. These usually went along with H2kHz*-H5kHz (Cantonese = 34, English = 31), and occasionally with F3 and F4 (Cantonese = 3, English = 3). In a similar vein, all talkers had a component consisting of H4*-H2kHz* s.d. and H2kHz*--H5kHz s.d., though it accounted for a smaller proportion of the total variation. \hl{Should I describe what these mean here? Or in the discussion?}

In the case of the moving standard deviation parameters, there were a few common configurations. Formant s.d. parameters often co-occurred. In both languages, the component typically consisted of F3 s.d. and F4 s.d. (Cantonese = 32, English = 26), though a subset of these cases also included F2 s.d. (Cantonese = 6, English = 10). In the case of spectral shape, the variable for H2*--H4* s.d. commonly occurred alone (Cantonese = 18, English = 18) or in combination with H1*--H2* s.d. (Cantonese = 13, English = 14). While the formant and spectral shape moving standard deviations often exhibited these common patterns, variables in these categories were just as likely to pattern in more idiosyncratic ways, loading alongside each other, F0, formants, and spectral measures. This kind of variability is not readily summarizable. 

The spectral noise parameters had a relatively consistent component structure across talkers and languages. Energy and Energy s.d. consistently loaded on the same component and were sometimes accompanied by F0 (Cantonese = 6, English = 2) and F0 s.d. (Cantonese = 1). CPP s.d. occurred consistently on its own component for all English PCAs, and 31 of the Cantonese PCAs. In the remaining three Cantonese PCAs, CPP s.d. was accompanied by CPP (n=1) or H1*-H2* s.d. (n=2). CPP patterned less consistently but was most often accompanied by F0 s.d. (Cantonese = 19, English = 14). SHR and SHR s.d. exclusively loaded together for 31 talkers in each language and SHR by itself for a single talker per language. The pair was sometimes accompanied by H1*-H2* (Cantonese = 2, English = 2), H2*-H4* (English = 1), or F0 (English = 3). 

While this covers many of the variables that went into the PCAs, F0 is notably sparse in the above paragraphs. While F0 s.d. was fairly consistent in emerging either with CPP (Cantonese = 21, English = 17) or alone (Cantonese = 9, English = 10), the same cannot be said for F0. No particular component structure with F0 occurred more than six times, and across the wide range of configurations, F0 was accompanied by all kinds of variables: F0 s.d., H1*--H2*, H1*--H2* s.d., H2*--H4*, F1 s.d., F4 s.d., CPP, Energy, Energy s.d., and SHR, SHR s.d. The lack of consistency in F0 across talkers is notable for a few reasons. First, F0 plays a major role in prior work on voice production and perception, given its salience as an acoustic dimension \citep{perrachione_2019_judgments}. A second reason for it being notable comes from Lee and colleagues' work, where F0 emerged as an important feature of acoustic voice variation structure in English spontaneous speech \citep{lee_2019_spontaneous} and Korean sentence reading \citep{lee_2020_language}, but not for English sentence reading \citep{lee_2019_acoustic}. 

On the whole, variables emerged on a single component. That is, very few variables had complex loading structures. Across talkers, only three had complex loading structures for H2*--H4* in each language. F0 and F0 s.d. participated in complex loadings for a single English talker, and twice in the Cantonese PCAs. The remaining variables that participated in complex loading structures only occurred in one or two PCAs across all talkers and languages. This means that for a given PCA, the interpretation of components is reasonably straightforward, even if drawing generalizations over the full group is not. 

There were additional components (not reported here) that were shared by less than half of the talkers. A full list of component configurations, along with the number of occurrences and range of variation accounted for is provided in the supplementary materials. \hl{Well... it will be! Also, would a table in this section help with interpretation? Or is prose plus supplementary materials good enough?}

In summary, this PCA analysis found a greater amount of component structure overlap than was reported in \citet{lee_2019_acoustic}. At the same time, idiosyncratic variation was still readily apparent in the PCAs, both in how variables co-occur, as well as in how much variance is accounted for by the different components. Additionally, it is important to remember that these PCAs represent the lower dimensional structure of the voices they measure. Considering that the total variance unaccounted for by the PCAs ranges from 17.3\%--25.1\%, this unaccounted for variability may also be idiosyncratic in nature. 

\subsection{Canonical redundancy analysis}\label{ch3:sec:cca}

\subsubsection{Methods}

To assess whether variation in a talker's voice is structurally similar across both languages, I compare PCA output from both languages by calculating redundancy indices in a canonical correlation analysis \citep[CCA][]{stewart_1968_canonical, jolliffe_2002_pca}. CCA is a statistical method used to explore how groups of variables relate to one another. The two sets of variables are transformed such that the correlation between the rotated versions is maximized. This is useful here, as a talker may have similar components in their English PCA and Cantonese PCA, but these components might not necessarily be in the same order, even if they account for comparable amounts of variance.

Redundancy is a relatively simple way to characterize the relationship between the loadings matrices of two PCAs---the two sets of variables under consideration here. For example, the two redundancy indices represent the amount of variation in a talker's Cantonese PCA output that can be accounted for via canonical variates by their English PCA output and vice versa. Notably, the two redundancy indices are not symmetrical \citep{stewart_1968_canonical}. This is particularly relevant in cases where the PCAs comprise different numbers of components, as determined by the stopping rule described above. The PCA with more components will likely account for more of the variation in a PCA with fewer components than the reverse.

Redundancy indices were computed for all pairwise combinations, including cases where similar values were expected (same talker, different language) and cases where dissimilarity was anticipated (different talker and language). Considering that the PCA analyses capture the lower-dimensional structure within each language, these redundancy indices effectively reflect the degree to which the lower-dimensional structure of acoustic voice variability is shared across a talker's two languages.

\subsubsection{Results}

Redundancy indices for within-talker comparisons ranged from 0.80 to 0.97, (\textit{Mdn} = 0.92, \textit{M} = 0.91, \textit{SD} = 0.04) and are displayed in Figure~\ref{ch3:fig:redundancy}, with the two redundancy indices for a given pairwise comparison plotted against one another. Comparisons across talkers within-language ranged from 0.64 to 0.96 (\textit{Mdn} = 0.83, \textit{M} = 0.83, \textit{SD} = 0.5). Comparisons across both talkers and languages ranged from 0.64 to 0.97 (\textit{Mdn} = 0.83, \textit{M} = 0.83, \textit{SD} = 0.5). Within-talker values were confirmed to be higher than across-talker comparisons, per a Welch's t-test (\textit{t}(70.93) = $-$17.35, \textit{p} $<$ 0.001, d = 1.77). A second Welch's t-test testing the same versus different language for the across talker comparisons did not find a difference between those groups (\textit{t}(4485.9) = $-$1.53, \textit{p} = 0.13, d = 0.05). 

While the across-talker comparisons were generally lower than the within-talker ones, the redundancy indices are overall still relatively high. The high values are not unexpected. As PCA is a dimensionality reduction technique, the discarded components almost certainly contain idiosyncratic variation. Moreover, and following from Section~\ref{ch3:sec:pca_results}, there were a substantial number of commonly occurring patterns across talkers and languages. Together, this supports the conceptualization of a voice space comprising a shared structure---as in the case of the prototype account---where voices can only deviate from one another so much.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.9\linewidth]{figures/ch3_redundancy.png} 
\caption{The relationship between the two redundancy indices for three different types of comparisons. Within-talker comparisons are represented by the black squares and are clearly clustered at the top right.}
\label{ch3:fig:redundancy}
\end{center}
\end{figure}

\subsection{Passage length analysis}\label{ch3:sec:passagelength}

As previewed in the introduction, passage length is an important consideration in the principal components and canonical redundancy analyses. It represents one possible reason why the results presented in this chapter differ from prior work. To examine the role of passage length, I conducted multiple PCAs for each talker and language combination, such that each PCA captured a progressively longer portion of the overall interview, using passage lengths comprising sample sizes of 500, 2000, 4500, 8000, 12500, 18000, 24500, 32000, 40500, 50000, 60500, and 72000. As the total number of samples per interview ranged from 20124 to 74638, there were six to 12 total PCAs per interview, depending on its maximum possible passage length. While the step sizes were somewhat arbitrarily selected, the goal was to give a more granular perspective on the lower end, while still covering the upper tail. Redundancy was expected to level off somewhere in the middle, as talkers should eventually cover their range of variability in a given style.

In these PCAs, the number of components was fixed at 10, the lowest number found in Section \ref{ch3:sec:pca_results}. This was done to put the PCAs on more equal footing in the subsequent analysis, given the asymmetries in CCA when different numbers of components were present. For each interview, the canonical redundancy indices were calculated for each talker and language combination, comparing PCAs for each passage length to the PCA for the longest passage length. All of this was done on a within-language and within-talker basis. The final comparison thus has perfect redundancy, as the longest PCA for a given interview is compared to itself.

\begin{figure}[htbp]
    \begin{center}
    \includegraphics[width=0.75\linewidth]{figures/ch3_passagelength.png} 
    \caption{Passage length redundancy indices are plotted against the sample size of the smaller PCA. Smoothed curves show a rapid increase in redundancy followed by a levelling off between the vertical orange lines, which represent the sample sizes used in prior work (x = 5000) and the present study (x = 20124).}
    \label{ch3:fig:passagelength}
    \end{center}
\end{figure}

Figure \ref{ch3:fig:passagelength} plots polynomial smooths for each interview, with superimposed mean smooths. The x-axis represents the sample size of the shorter passage length in the comparison. The y-axis represents an average of the two redundancy indices. The vertical line at 5000 represents the average sample size from \citet{lee_2019_acoustic}. The vertical line at 20124 represents the sample size used in Sections \ref{ch3:sec:pca} and \ref{ch3:sec:pca_results}. While there are some gains in sample sizes above the second vertical line, they are comparatively small. It is readily apparent from this plot that the sample size used for PCAs in this chapter was sufficient to capture most of the range of talkers' within-interview variability. As the leveling-off point likely varies across speech styles, it is not immediately apparent whether the sample size in \citet{lee_2019_acoustic} sufficiently captured the range of talker variability and thus may not adequately capture the structure of their variability. 

\section{Discussion and conclusion}\label{ch3:sec:discussion}

This chapter examines spectral properties and structural similarities in an individual's voice across two languages. To this end, it uses conversational interviews from the SpiCE corpus of speech in Cantonese and English, described in Chapter \ref{ch2:corpus}. The analyses presented in this chapter cover three different exploratory approaches to the question of understanding crosslinguistic (dis)similarity in bilingual voices. Section \ref{ch3:sec:comparison} takes a coarse perspective, comparing overall distributions using \textit{t}-tests and Cohen's \textit{d} values. This approach follows from a body of literature focused on crosslinguistic comparisons of acoustic measurements---primarily F0---using means, ranges, and standard deviations to describe how voices differ (or not). Section \ref{ch3:sec:pca} replicates \citeauthor{lee_2019_acoustic}'s \citeyearpar{lee_2019_acoustic} methods for drilling down into the structure of acoustic voice variation using PCAs and extends it to the case of bilingual speech. Section \ref{ch3:sec:cca} builds on the PCAs and introduces canonical redundancy as a metric for objectively assessing crosslinguistic similarity from the output of two PCAs. These methods are then extended in Section \ref{ch3:sec:passagelength} to demonstrate that the analysis used a sufficiently large sample.

A clear result in this chapter is that the bilinguals studied here exhibit similar spectral properties and similar lower-dimensional structure in their acoustic voice variation. This similarity is most apparent on a within-talker basis but still present across talkers and languages, despite substantial segmental and suprasegmental differences across English and Cantonese \citep{matthews_2013_cantonese}. In this sense, the SpiCE corpus talkers appear to have the same ``voice'' in each of the two languages. This outcome supports the characterization of voices as auditory faces. The face-voice comparison is especially apt if you take into account findings that talkers' faces vary across languages, as evidenced by work demonstrating that lip movement patterns alone are sufficient for humans and machines to identify and discriminate between spoken languages \citep{afouras_2020_now, sotofaraco_2007_discriminating}. Voices and faces are highly similar across languages but are not necessarily identical---this leaves room for individuals who are familiar with both the individuals and languages in question to excel at perceptual tasks in both domains.

It is reassuring that the results from the first two approaches used here reflect prior findings. For example, when there was a difference for measures like F0 or H1*--H2*, it tended to mirror expectations from the literature that Cantonese tends to have lower pitch and breathier voice quality than English \citep{ng_2012_ltas, ng_2010_voice}. At the same time, most talkers did not exhibit a meaningful difference, validating prior work that found no differences \citep{altenberg_2006_f0}. The variability present in this particular sample of 34 talkers highlights the need to treat very small studies with some level of skepticism.

In the PCAs, similarity to prior work emerges in the structure of various components, including the ones that account for the most variability. \citet{lee_2019_acoustic} report that three of the largest components captured lower-dimensional structure for (i) higher harmonic spectral shape variation, (ii) higher formants, and (iii) a combination of lower spectral shape with the lower formants. While the amount of overall variance accounted for differs here, these component structures also occurred for the SpiCE talkers. Respectively, they are associated with (i) perceived breathiness or brightness, (ii) vocal tract size or speaker identity, and (iii) a combination of phonation type and vocal tract configuration---perhaps reflecting shared linguistic variation. The cross-study overlap in component structure adds credibility to the idea of a prototype model in voice \citep{lavner_2001_prototype, latinus_2011_voice}. Much like \citet{lee_2019_acoustic}, the key shared dimensions relate to the timbre, identity, and vocal tract configuration.

\begin{figure}[htbp]
    \begin{center}
    \includegraphics[width=0.9\linewidth]{figures/ch3_redundancybyttestdiff_5in.png} 
    \caption{The absolute value of the difference of means is plotted against the average redundancy value for each talker. Color and shape indicate the size of Cohens' \textit{d}. The superimposed regression line summarizes the relationship between these values.}
    \label{ch3:fig:diffbyred}
    \end{center}
\end{figure}

This high degree of similarity does not preclude crosslinguistic differences on a within-talker basis but rather suggests that such differences occur on a more global level. This is apparent in Figure \ref{ch3:fig:diffbyred}, which depicts the relationship between talkers' average redundancy from Section \ref{ch3:sec:cca} and the difference between the mean values for each of the acoustic measurements in Section \ref{ch3:sec:comparison}. If there were clear relationships between large crosslinguistic differences and redundancy, the regression lines should be strongly negative---this does not seem to be the case.

Such high similarity in the PCAs was not entirely expected, given the results of \citet{lee_2019_acoustic}, where a handful of shared components were evident but were complemented by numerous idiosyncratic components. At face value, the results in this chapter suggest that a heterogeneous bilingual population has more across-talker similarity than a tightly controlled group of monolingual English speakers. Several analysis decisions may have contributed to this apparent difference. I compared similar components independent of order, which ignores the fact that similar components may account for different amounts of variance, but ensures that comparisons are made among like items. Any downside to this methodological decision is mitigated by the fact that most components made relatively small contributions in how much of the overall variance they accounted for (see Table \ref{ch3:tab:componentcount}). As such, I predict that increased across-talker similarity would be found in a reanalysis of the UCLA Speaker Variability Database \citep{keating_2019_database} using the adapted methods of this chapter. 

While methodological choices may account for some part of these results, the data differences between the current chapter and previous studies are also pertinent. This chapter uses substantially longer passages than the short samples in \citet{lee_2019_acoustic}. Larger speech samples clearly allow for a stable underlying structure to emerge. Smaller samples, conversely, may reflect more ephemeral variation in a talker's voice, and thus not be representative of the talker's full range. The passage length analysis in this chapter shows that the number of samples needed for stabilization is substantially larger than the 5000 samples used in \citet{lee_2019_acoustic}. This does not necessarily discount their work, however, as the current chapter uses spontaneous speech, which is arguably more variable than read speech.\footnote{While it is true that \citet{} examined spontaneous speech, the poster only states that two minutes of speech were used for each participant. By this estimation, the sample size was likely on the lower side, compared to the 20-25 minute interviews in the SpiCE corpus. However, it is not possible to make a direct comparison without knowing the number of samples.} It's plausible that an analysis of sentence reading would not need as much data to cover talkers' range of variability in reading aloud. The body of literature in the introduction establishes differences in voice quality across speaking styles \citep[e.g.,][]{lee_2017_bilingual}. As such, the threshold suggested here may only be appropriate for the speaking style of peer-to-peer conversational interviews. In any case, the methods presented here offer a tool for researchers to use in assessing whether their sample size is representative of a larger whole. Understanding how this interacts with speaking style is left for future directions. 

Ultimately, the goal of this line of research is to understand how the acoustic variability and structure of talkers' voices maps onto listeners' organization of a voice space for use in talker recognition and discrimination. Turning to listener and behavioral data will help in deciphering what is meaningful variation within a voice from low-level noise that cannot be attributed to a particular vocal signature. Verification from listener performance will help adjudicate which statistical choices present an acoustic voice space that matches listener organization. The results of this chapter set up predictions for that work. These predictions will be revisited in general discussion.

\endinput % -------------------------------------------------------- %
