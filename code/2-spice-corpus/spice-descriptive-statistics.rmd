---
title: "SpiCE Descriptive Statistics"
author: "Khia A. Johnson"
date: "5/21/2021"
output: html_document
---

# Chapter 2: The SpiCE Corpus

This file accompanies chapter 2 of my dissertation. It includes descriptive statistics and data visualization summarizing the participants and contents of the corpus in broad strokes.

---
## Setup
Import packages
```{r message=FALSE}
library(tidyverse)
library(ggthemes)
library(GGally)
library(ggrepel)
# library(tidylog)
library(DBI)
library(viridis)
```

Set visualization defaults
```{r}
theme_set(theme_clean() + theme(
      legend.title = element_text(face = 'bold', size=10),
      legend.text = element_text(size=10),
      legend.position = 'bottom',
      axis.title.x = element_text(size = 10, face='bold'),
      axis.title.y = element_text(size = 10, face='bold'),
      strip.text = element_text(size=10, face='bold'),
      plot.background = element_blank()
    ))

# ggplot <- function(...) ggplot2::ggplot(...) + 
#     scale_color_colorblind() +
#     scale_fill_colorblind()
```

Connect to SpiCE SQLite database
```{r}
db <- dbConnect(RSQLite::SQLite(), "../1-general/spice.db")
dbListTables(db)
```

Load the words and tasks tables, and join
```{r}
words <- dbReadTable(db, "words")
tasks <- dbReadTable(db, "tasks")
phones <- dbReadTable(db, "phones")
phones
```

Query the full word table merged with task by time stamps
```{r}
results <- dbSendQuery(
    db,
    "SELECT word,
	       word_onset,
	       word_offset,
	       task,
	       task_onset,
	       task_offset,
	       words.file
	FROM words
	LEFT JOIN tasks ON (tasks.file = words.file
	                    AND word_onset BETWEEN task_onset AND task_offset)"
    )
words <- fetch(results)

words <- words %>%
    separate(file, into = c('talker','language','order','date'), remove = FALSE)
```


## Corpus Summary
### Assess code-switching from utterances level
```{r}

results <- dbSendQuery(
    db,
    "SELECT utterance,
	       utterance_onset,
	       utterance_offset,
	       task,
	       task_onset,
	       task_offset,
	       utterances.file
	FROM utterances
	LEFT JOIN tasks ON (tasks.file = utterances.file
	                    AND utterance_onset BETWEEN task_onset AND task_offset)"
    )
utts <- fetch(results)

utts <- utts %>%
    separate(file, into = c('talker','language','order','date'), remove = FALSE)

utts
```

```{r}
wordtcs <- utts %>%
    filter(task == 'interview') %>%
    select(utt=utterance, talker, interview=language) %>%
    mutate(
        utt = str_replace_all(utt, '\\s*[@＠]\\s*', '@'),
        utt = str_replace_all(utt, '[】 【]', ' '),
        utt = str_replace_all(utt, '\\s+', ' '),
        utt = str_replace(utt, '^\\s+', ''),
        utt = str_replace(utt, '\\s+$', '')
        ) %>%
    separate_rows(utt, sep = '\\s+') %>%
    group_by(utt, talker, interview) %>%
    summarise(n=n()) %>%
    mutate(
        utt = str_replace_all(utt, '[\\?}@＠]$', ''),
        type = if_else(str_starts(utt, '&'), 'Fragment', NULL),
        type = if_else(str_detect(utt, '@'), 'Other Language', type), 
        type = if_else(str_starts(utt, '[a-z]') & str_ends(utt, '[0-9]'), 'Cantonese', type), 
        type = if_else(str_detect(utt, "^[a-z'-]+$"), 'English', type), 
        type = if_else(utt == 'xxx', 'Unintelligible', type),
        type = if_else(is.na(type), 'Cantonese', type)
    ) %>%
    filter(utt != '', str_starts(utt, '@', negate = TRUE)) %>%
    select(word = utt, talker, interview, n, type)
```


```{r}
wordtypecounts <- wordtcs %>%
    group_by(interview, talker, type) %>%
    summarise(n=sum(n)) %>%
    ungroup()
```

```{r, fig.width=5, fig.height=7}
wordtypecounts %>%
    filter(interview=='Cantonese') %>%
    ggplot(aes(fill=type, x=talker, y=n)) + 
    geom_col() + 
    scale_fill_viridis_d(option='magma', begin = 0.9, end = 0,
                         limits = c('Cantonese','English','Other Language', 'Fragment', 'Unintelligible')) + 
    xlab('Talker') +
    ylab('Number of words') +
    theme(axis.text.x = element_text(angle = 90),
          legend.position="bottom",
          legend.title = element_blank(),
          legend.text = element_text(size=6)) 

ggsave('../../text/figures/ch2_cantonesetypecounts_5in.png', width = 5, height = 6.5)
```

```{r, fig.width=5, fig.height=7}
wordtypecounts %>%
    filter(interview=='English') %>%
    ggplot(aes(fill=type, x=talker, y=n)) + 
    geom_col() + 
    scale_fill_viridis_d(option='magma', begin = 0.9, end = 0,
                         limits = c('Cantonese','English','Other Language', 'Fragment', 'Unintelligible')) + 
    xlab('Talker') +
    ylab('Number of words') +
    theme(axis.text.x = element_text(angle = 90),
          legend.position="bottom",
          legend.title = element_blank(),
          legend.text = element_text(size=6)) 

ggsave('../../text/figures/ch2_englishtypecounts_5in.png', width = 5, height = 6.5)
```

```{r}
wordtcs %>%
    ungroup() %>%
    select(word,interview) %>%
    unique() %>%
    group_by(interview) %>%
    summarise(n()) 
```

```{r}
wordtcs %>%
    group_by(interview, talker) %>%
    summarise(tokens = sum(n), types = n()) %>%
    group_by(interview) %>%
    summarise(sum(tokens),mean(tokens),sd(tokens), min(tokens),max(tokens), 
             mean(types),sd(types), min(types),max(types))
```


```{r}
wordtcs %>%
    group_by(talker, interview, type) %>%
    summarise(n=sum(n)) %>%
    pivot_wider(names_from = 'type', values_from = 'n') %>%
    filter(Cantonese<10)
```

English and Canto token frequency in the English sessions

```{r}
wordtcs %>%
    filter(type =='English' | type == 'Cantonese', interview=='Cantonese') %>%
    mutate(type = if_else(type=='Cantonese', 'Cantonese in\nCantonese interview', 'English in\nCantonese interview')) %>%
    group_by(word, interview, type) %>%
    summarise(n = sum(n)) %>%
    ungroup() %>%
    mutate(log_frequency = log(n)) %>%
    ggplot(aes(x=log_frequency)) + 
        geom_histogram(binwidth = 0.5) + 
        facet_wrap(~type) +
        xlab('Log Frequency') + 
        ylab('Count')

ggsave('../../text/figures/ch2_cantonesewordfrequency_5in.png', width = 5, height = 3)

wordtcs %>%
    filter(type =='English' | type == 'Cantonese', interview=='English') %>%
    mutate(type = if_else(type=='Cantonese', 'Cantonese in\nEnglish interview', 'English in\nEnglish interview')) %>%
    group_by(word, interview, type) %>%
    summarise(n = sum(n)) %>%
    ungroup() %>%
    mutate(log_frequency = log(n)) %>%
    ggplot(aes(x=log_frequency)) + 
        geom_histogram(binwidth = 0.5) + 
        facet_wrap(~type) +
        xlab('Log Frequency') + 
        ylab('Count')

ggsave('../../text/figures/ch2_englishwordfrequency_5in.png', width = 5, height = 3)

```







Plot log word frequency for both languages, excluding instances of <unk>
```{r fig.width=6, fig.height=3}
words %>%
    filter(word != '<unk>') %>%
    group_by(language, word) %>%
    summarise(frequency = n()) %>%
    ungroup() %>%
    mutate(log_frequency = log(frequency)) %>%
    ggplot(aes(x=log_frequency)) + 
        geom_histogram(binwidth = 0.5) + 
        facet_wrap(~language) +
        xlab('Log frequency') +
        ylab('Count')

ggsave('../../text/figures/ch2_wordfrequency_5in.png', width = 5, height = 3)
```

Hours of actual participant speech production -- excludes all pauses as this number is based purely on where the forced aligner identified words
```{r}
words %>%
    mutate(word_dur = word_offset - word_onset) %>%
    group_by(language) %>%
    summarise(sum(word_dur)/60/60)
```

Proportion of unknown words by talkers; an estimate of code-switching, as unknown words are almost always words in a different language.
The first plots shows the proportion based on a count, and the second based on duration.
```{r fig.width=3, fig.height=3}
unk_count <- words %>%
    mutate(is_unknown = word == '<unk>') %>%
    group_by(talker, language, is_unknown) %>%
    summarise(count_words = n()) %>%
    pivot_wider(names_from = is_unknown, values_from=count_words) %>%
    mutate(proportion_unknown = `TRUE`/(`TRUE`+`FALSE`)) %>%
    select(talker, language, proportion_unknown) %>%
    pivot_wider(names_from=language, values_from=proportion_unknown) 

unk_duration <- words %>%
    mutate(is_unknown = word == '<unk>', word_dur = word_offset-word_onset) %>%
    group_by(talker, language, is_unknown) %>%
    summarise(duration = sum(word_dur)) %>%
    pivot_wider(names_from = is_unknown, values_from=duration) %>%
    mutate(proportion_unknown = `TRUE`/(`TRUE`+`FALSE`)) %>%
    select(talker, language, proportion_unknown) %>%
    pivot_wider(names_from=language, values_from=proportion_unknown) 

# ggparcoord(unk_count, columns = 2:3,
#     scale="globalminmax",
#     showPoints = TRUE,
#     alphaLines = 0.5
#     ) + xlab('Language') + ylab('Proportion')

ggparcoord(unk_duration, columns = 2:3,
    scale="globalminmax",
    showPoints = TRUE,
    alphaLines = 0.5,
    ) + xlab('Language') + ylab('Proportion') +
    scale_y_continuous(limits = c(0,.3),breaks = c(0,0.05,0.1,.15,.2,.25,.3))

ggsave('../../text/figures/ch2_switchfrequency_4in.png', width = 4, height = 3)
```


```{r}
results <- dbSendQuery(
    db,
    "SELECT phone,
	       phone_onset,
	       phone_offset,
	       task,
	       task_onset,
	       task_offset,
	       phones.file
	FROM phones
	LEFT JOIN tasks ON (tasks.file = phones.file
	                    AND phone_onset BETWEEN task_onset AND task_offset)"
    )
phones <- fetch(results)

phones
```

```{r}
phones %>%
    filter(phone != 'sil', phone != 'sp') %>%
    mutate(dur = phone_offset - phone_onset) %>%
    group_by(file, task) %>%
    summarise(minutes = sum(dur)/60) %>%
    separate(file, into = c('talker','language')) %>%
    mutate(task = if_else(task=='sentence', 'sentences', task)) %>%
    group_by(language, task) %>%
    summarise(total_hrs = sum(minutes)/60, total_min = sum(minutes))
    #pivot_wider(names_from = task, values_from = minutes)
```


The Cantonese recordings include 8.3 hours of speech: 13.6 minutes of sentences, 44.0 minutes of storyboard narration, and 7.4 hours of conversational interview. These estimates are calculated from the summed duration of all non-silent intervals in the phone tier of the transcripts, and as such, do not include interviewer questions or any pauses in the participant's speech. 

Using the same estimation technique as used for Cantonese, the English recordings include 8.9 hours of speech: 21.9 minutes of sentences, 45.7 minutes of storyboard narration, and 7.7 hours of conversational interview speech.





Clear and close the database
```{r}
dbClearResult(results)
dbDisconnect(db)
rm(db, results)
```

## Participant summary

Load the data
```{r message=FALSE, warning=FALSE}
lbq_summary <- read_csv('~/Corpora/spice/info/participants/spice-lbq-summary.csv')
lbq_raw <- read_csv('~/Corpora/spice/info/participants/spice-lbq-detailed.csv')
```

```{r}
demographics <- lbq_raw %>% 
    select(!matches("language"), -X253) 
```

```{r fig.width=5, fig.height=4}
demographics %>%
    select(id, starts_with('Places')) %>%
    mutate(across(where(is.character), 
                  ~ str_replace_all(., 'BC |AB |ON |Quebec|CA |London |Macau|Kansai |Kanto ', ''))) %>%
    pivot_longer(-id, names_to = 'Ages') %>%
    mutate(Ages = as_factor(str_replace(Ages, 'Places lived ages', 'Ages'))) %>%
    separate(value, into = c('a','b','c'), sep = ' - ') %>%
    pivot_longer(cols = a:c, values_to = 'Place') %>%
    select(id, Place, Ages) %>%
    arrange(Place) %>%
    drop_na() %>%
    ggplot(aes(y=fct_rev(Place))) +
        geom_bar() +
        facet_wrap(~Ages, ncol=2) +
        ylab('Country Lived In') +
        xlab('Count') +
        theme(legend.position = 'none')

ggsave('../../text/figures/ch2_placeslived_5in.png', width = 5, height = 4)
```

```{r}
demographics %>%
    select(id, contains('Caretaker')) %>%
    pivot_longer(-id, values_to = 'Place') %>%
    mutate(name = str_replace(name, 'Caretakers - Region ','')) %>%
    separate(name, into = c('Question', 'Caretaker'), sep = ' - ') %>%
    pivot_wider(names_from = 'Question', values_from = 'Place') %>%
    drop_na() %>%
    mutate(born = str_replace(born,'Manila|Ilocos ', '')) %>%
    mutate(born = str_replace(born,'[A-Za-z]+ China', 'China')) %>%
    group_by(born) %>%
    summarise(n=n()) %>%
    arrange(born) %>%
    
    ggplot(aes(x=n, y=reorder(born, n))) +
        geom_col() +
        xlab('Count') +
        ylab('Caretaker(s) born in')

ggsave('../../text/figures/ch2_caretakers_3in.png', width = 3, height = 3)

```


```{r}
lang_nums <- lbq_raw %>% 
    select(id, matches("^Language [0-9]$")) %>%
    pivot_longer(`Language 1`:`Language 9`, names_to = "lang_num", values_to = "language") %>%
    drop_na()

tidy_languages <- lbq_raw %>% 
    select(id, matches("- Language [0-9]$")) %>%
    mutate(across(where(is.character), ~recode(.,`Excellent` = '4', 
                                               `Good` = '3',
                                               `Fair` = '2',
                                               `Elementary` = '1',
                                               `No proficiency` = NULL,
                                               `Daily` = '365',
                                               `Weekly` = '52',
                                               `Monthly` = '12',
                                               `Yearly` = '1',
                                               `Less than once a year` = '0.5',
                                               `Never` = NULL,
                                               `n/a` = NULL
                                               ))) %>%
    mutate(across(-id, as.numeric)) %>%
    pivot_longer(-id) %>%
    separate(name, into = c('question','lang_num'), sep = -10 , extra = 'merge') %>%
    drop_na() %>%
    left_join(lang_nums, by = c('id','lang_num')) %>%
    select(id, question, language, value) %>%
    mutate(question = str_replace(question, ' - $', ''),
           question = str_replace(question, '/', 'or'))

rm(lang_nums)
```

Visualize the age that each participant started learning each of their languages
```{r fig.height=9, fig.width=5}
tidy_languages %>%
    filter(question=='Age Started', language!='French (Quebec)') %>%
    select(Participant=id, Language=language,Age=value) %>%
    mutate(Age = if_else(Age>=20, 20, Age)) %>%
    mutate(Language = if_else(Language=='Bahasa Indonesia', 'Indonesian', Language)) %>%
    mutate(Language = if_else(Language=='Taiwanese Hokkien', 'Hokkien', Language)) %>% 
    mutate(Language = if_else(Language=='Hokkien Taiwanese', 'Hokkien', Language)) %>% 
    mutate(Language = if_else(Language=='French (France)', 'French', Language)) %>%
    arrange(Language, Age) %>%
    filter(str_starts(Participant,'VF')) %>%
    ggplot(aes(y=Age, x='', color = Age, label=Language)) +
        geom_point(size=2, shape=18) +
        geom_text_repel(max.iter=100000, min.segment.length = 0,
                        box.padding = 0.4, force=2, size=2.5, max.overlaps = 10) +
        scale_y_continuous(limits = c(-4,22), breaks = c(0,5,10,15,20), 
                           labels = c('0', '5', '10','15', '20+'))+
        scale_color_viridis_c(option='magma', begin = 0, end = 0.8) + 
        facet_wrap(~Participant, ncol = 3) +
        xlab('')+
        ylab('Age Started Learning Language (Year)') +
        theme(panel.border = element_rect(fill=NA), 
              legend.position = 'none',
              strip.text = element_text(size = 8, face = 'bold'))

# ggsave('../../text/figures/ch2_multilingualism_vm_5in.png', width = 5, height = 7)
ggsave('../../text/figures/ch2_multilingualism_vf_5in.png', width = 5, height = 7)
```



---