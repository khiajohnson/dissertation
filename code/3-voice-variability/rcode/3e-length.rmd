---
title: "3d-length"
author: "Khia A. Johnson"
date: "8/17/2021"
output: html_document
---

This file accompanies the passage length analysis in Chapter 3.

---

# Setup

Imports
```{r}
library(tidyverse)
library(ggthemes)
library(ggrepel)
library(parameters)
library(candisc)
library(data.table)
library(psych)
```

Load data
```{r}
df <- fread('../data/spice_voicesauce_processed.csv', sep = ',') 
```

Viz defaults
```{r}
theme_set(theme_clean() + theme(
      legend.title = element_text(face = 'bold', size=10),
      legend.text = element_text(size=10),
      legend.position = 'bottom',
      axis.title.x = element_text(size = 10, face='bold'),
      axis.title.y = element_text(size = 10, face='bold'),
      strip.text = element_text(size=10, face='bold'),
      plot.background = element_blank()
    ))
```

# PCAs with variable passage length

## Run

Function to get the PCA loadings for a subset of the big dataframe
```{r}
run_pca <- function(one_talker_df, filename, n=0) {

  # run the pca
  tX <- one_talker_df[,10:33]
  if (n>0) {
    n_components <- n
  } else {
    tX_pca_all <- principal_components(tX, n='all', rotation = "promax", standardize = TRUE)
    tX_var_all <- summary(tX_pca_all)
    tX_var_all <- rownames_to_column(setNames(data.frame(t(tX_var_all[,-1])), tX_var_all[,1]), 'Component')
    n_components <- nrow(filter(tX_var_all, Eigenvalues > mean(tX_var_all$Eigenvalues)*0.7))
  }
  tX_pca <- principal_components(tX, n = n_components, rotation = "promax", standardize = TRUE) 

  # add summary information and wrangle
  tX_var <-summary(tX_pca)
  tX_var <- rownames_to_column(setNames(data.frame(t(tX_var[,-1])), tX_var[,1]), 'Component')
  tX_pca <- as_tibble(tX_pca) %>% 
    pivot_longer(cols = starts_with('RC'), names_to = 'Component', values_to = "Loading") %>%
    left_join(tX_var, by = 'Component') %>%
    drop_na() %>%
    mutate(File=filename) %>%
    select(File, Variable, Component, Loading, Eigenvalues, Variance, Variance_Proportion, Complexity, Uniqueness, MSA)
  
  # clean up
  if (n>0) {
    rm(tX, tX_var)    
  } else {
    rm(tX, tX_pca_all, tX_var_all, tX_var)
  }

  return(tX_pca)
}

get_pca_loadings_tibble_pl <- function(f) {
  m <- pl_results %>%
    filter(File==f) %>%
    select(Variable, Var_Order, Loading) %>%
    arrange(Var_Order, Variable) %>%
    pivot_wider(names_from = Var_Order, values_from = Loading)
  return(m[,2:ncol(m)]) 
}
```

Set the possible sample sizes
```{r}
lengths <- c(500, 2000, 4500, 8000, 12500, 18000, 24500, 32000, 40500, 50000, 60500, 72000)
```

Run PCAs with fixed number of components and save the outpus
```{r}
files <- unique(df$File)[21:68]
# pl_list_results <- list()

for (f in files) {
  this_file <- filter(df, File==f)
  print(f)
  longest <- nrow(this_file)
  print(longest)
  
  for (l in lengths) {
    if (l < longest) {
      try({
        this_length <- slice_head(this_file, n=l)
        this_combo = paste0(f,'_L',l)
        this_pca <- run_pca(this_length, this_combo, n=10)
        pl_list_results[[this_combo]] <- this_pca
      })
    }
  }
  
}

pl_results <- bind_rows(pl_list_results)

pl_variance_orders <- pl_results %>%
  group_by(File, Component, Variance) %>%
  summarize() %>%
  group_by(File) %>%
  arrange(desc(Variance)) %>%
  mutate(number=1, Var_Order=cumsum(number)) %>%
  arrange(File) %>%
  select(File, Component, Var_Order)%>%
  ungroup()

pl_results <- left_join(pl_results, pl_variance_orders, by=c('File', 'Component'))

fwrite(pl_results, '../data/passage_length_pca_results.csv', sep = ',')

```

Load the pca results if already run
```{r}
pl_results <- read_csv('../data/passage_length_pca_results.csv')
```

Generate list of all the pairs to test and calculate redundancy.
```{r}
all_pairs <- tibble(V1 = unique(pl_results$File)) %>%
  separate(V1, sep='_I[12]_[0-9]+_', into = c('File','Length'), remove=FALSE) %>%
  group_by(File) %>%
  mutate(V2 = tail(V1, 1)) %>%
  ungroup() %>%
  select(V1, V2)

# calc redundancy
xs <- list()
ys <- list()
px <- list()
py <- list()

for (i in 1:nrow(all_pairs)) {

  x_file <- all_pairs[[i, 1]]
  y_file <- all_pairs[[i, 2]]
  this_CCA <- cancor(
    x=get_pca_loadings_tibble_pl(x_file),
    y=get_pca_loadings_tibble_pl(y_file))
  this_red <- redundancy(this_CCA)

  px[[i]] <- x_file
  py[[i]] <- y_file
  xs[[i]] <- this_red$X.redun
  ys[[i]] <- this_red$Y.redun
  }

pl_all_redundancy <- as_tibble(cbind(px,py,xs,ys)) %>% 
  unnest(c(px,py,xs,ys))

rm(px,py,xs,ys, x_file, y_file, this_CCA, this_red)

fwrite(pl_all_redundancy, '../data/passage_length_redundancy_results.csv', sep = ',')
```

Load if already run
```{r}
pl_all_redundancy <- read_csv('../data/passage_length_redundancy_results.csv')
```

## Visualize

Plot how redundancy changes over the course of changing passage length
```{r fig.width=5, fig.height=3}
pl_all_redundancy %>%
    separate(py, into = c('Talker','Language')) %>%
    mutate(size = as.numeric(str_extract(px, '[0-9]+$'))) %>%
    pivot_longer(cols = xs:ys) %>%
    ggplot(aes(x=size, y=value)) +
    # geom_point(size=0.1, aes(group=factor(paste(Talker,Language))) ) +
    geom_line( color='black', size=0.05, aes(group=factor(paste(Talker,Language,name)))) +
    geom_smooth(method = 'gam', color='black', se=FALSE, size=2, ) +
    scale_y_continuous(limits = c(0,1)) +
    theme_clean() +
    geom_vline(xintercept = 20124, color='orange') +
        geom_vline(xintercept = 12000, color='orange') +

    geom_vline(xintercept = 5150, color='orange') +
    xlab('Sample Size') +
    ylab('Redundancy') +
  facet_wrap(~Language, ncol=2) +
  theme(strip.text = element_text(face='bold'))

# ggsave('../../../text/figures/ch3_passagelength.png', width = 5, height = 3)

```

