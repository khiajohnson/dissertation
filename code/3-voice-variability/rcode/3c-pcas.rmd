---
title: 'Chapter 3: PCAs for varying passage lengths'
author: "Khia A. Johnson"
date: "7/23/2021"
output: html_document
---

# Imports & load data
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ggthemes)
library(ggrepel)
library(parameters)
library(candisc)
library(data.table)
```

Set visualization defaults
```{r}
theme_set(theme_clean() + theme(
      legend.title = element_text(face = 'bold', size=10),
      legend.text = element_text(size=10),
      legend.position = 'bottom',
      axis.title.x = element_text(size = 10, face='bold'),
      axis.title.y = element_text(size = 10, face='bold'),
      strip.text = element_text(size=10, face='bold'),
      plot.background = element_blank()
    ))
```

Load the data
```{r}
df <- fread('../data/spice_voicesauce_processed.csv', sep = ',') 
grouping_vars <- read_csv('../data/spice_grouping_vars.csv')
```



Summarize range of samples across interviews
```{r}
df %>%
    group_by(File) %>%
    summarise(n=n()) %>%
    ungroup() %>%
    summarise(min(n), median(n), max(n))
```

```{r}
df_trunc <- df %>%
    group_by(File) %>%
    slice_head(n=20124)
nrow(df_trunc)
```

Function to run PCA for a single talker with promax rotation/standardization and process the output
```{r}
run_pca <- function(one_talker_df, filename, n=0) {

  # run the pca
  tX <- one_talker_df[,10:33]
  if (n>0) {
    n_components <- n
  } else {
    tX_pca_all <- principal_components(tX, n='all', rotation = "promax", standardize = TRUE)
    tX_var_all <- summary(tX_pca_all)
    tX_var_all <- rownames_to_column(setNames(data.frame(t(tX_var_all[,-1])), tX_var_all[,1]), 'Component')
    n_components <- nrow(filter(tX_var_all, Eigenvalues > mean(tX_var_all$Eigenvalues)*0.7))
  }
  tX_pca <- principal_components(tX, n = n_components, rotation = "promax", standardize = TRUE) 

  # add summary information and wrangle
  tX_var <-summary(tX_pca)
  tX_var <- rownames_to_column(setNames(data.frame(t(tX_var[,-1])), tX_var[,1]), 'Component')
  tX_pca <- as_tibble(tX_pca) %>% 
    pivot_longer(cols = starts_with('RC'), names_to = 'Component', values_to = "Loading") %>%
    left_join(tX_var, by = 'Component') %>%
    drop_na() %>%
    mutate(File=filename) %>%
    select(File, Variable, Component, Loading, Eigenvalues, Variance, Variance_Proportion, Complexity, Uniqueness, MSA)
  
  # clean up
  if (n>0) {
    rm(tX, tX_var)    
  } else {
    rm(tX, tX_pca_all, tX_var_all, tX_var)
  }

  return(tX_pca)
}
```


Using the function `run_pca()` function defined above, does PCA separately for each Talker/Language combo, and saves to `list_results`. *Note: prints file names as they finish running.*
```{r fig.height=4, fig.width=4}
list_results <- list()
files <- unique(df_trunc$File)

for (f in files) {
  this_file <- df_trunc %>% filter(File==f)
  this_pca <- run_pca(this_file, f)
  list_results[[f]] <- this_pca
  print(f)
}
```

```{r}
saveRDS(list_results, file='../data/pca_results_truncated.rds')
list_results <- readRDS(file='../data/pca_results_truncated.rds')
```


Wrangle the `list_results` object into a more useable dataframe, and save it.  
```{r message=FALSE, warning=FALSE}
results <- bind_rows(list_results)

results <- results %>%
  separate(File, into = c('Talker', 'Language', 'Order'), remove=FALSE) %>%
  left_join(grouping_vars, by='Variable') %>%
  group_by(File, Component) %>%
  arrange(desc(abs(Loading))) %>%
  mutate(number = 1, Bar_Order = cumsum(number)) %>%
  ungroup

variance_orders <- results %>%
  group_by(File, Component, Variance) %>%
  summarize() %>%
  group_by(File) %>%
  arrange(desc(Variance)) %>%
  mutate(number=1, Var_Order=cumsum(number)) %>%
  arrange(File) %>%
  select(File, Component, Var_Order)%>%
  ungroup

results <-left_join(results, variance_orders, by=c('File', 'Component'))
write_csv(results, '../data/pca_results_truncated.csv')
```

Clean up intermediate and auxiliary things
```{r}
rm(this_file, this_pca, f,variance_orders, grouping_vars)
```


**cleaned up code until here**

## Analyze PCA results
```{r}
results <- read_csv('../data/pca_results_truncated.csv')
```

Function to plot loadings
```{r, fig.width=4, fig.height=6}
return_loadings_plot <- function(subset) {
  
  subset <- subset %>%
    mutate(Loading= abs(Loading),
           Variable = str_replace(Variable, '_sd', ' s.d.'),
           Variable = str_replace(Variable, 'H1H2c', 'H1*-H2*'),
           Variable = str_replace(Variable, 'H2H4c', 'H2*-H4*'),
           Variable = str_replace(Variable, 'H42Kc', 'H4*-H2kHz*'),
           Variable = str_replace(Variable, 'H2KH5Kc', 'H2kHz-H5kHz*'))
  
  lplot <- ggplot(subset, aes(y=Loading, x=Bar_Order, fill=Category, label=Variable)) +
      geom_col() +
      scale_fill_viridis_d(option='magma', begin = 0, end=0.75) +
      geom_text(angle=90, nudge_y = -0.5*(subset$Loading), colour = "white", fontface = "bold", size=1.9)+
      geom_label(aes(label=paste('Var:\n', round(Variance,3))), x= 0.6*max(subset$Bar_Order), y=-0.15, size=1.9, fill='white') +
      scale_y_continuous(limits = c(-0.25,1.1)) +
      facet_grid(Language~Var_Order) +
      theme_clean() +
      ylab('Loading (absolute value)') +
      xlab('') +
      theme(strip.text = element_text(face='bold', size=6),
            axis.text.x = element_blank(),
            axis.ticks.x = element_blank(),
            axis.title.x = element_blank(),
            legend.position = 'bottom',
            legend.title = element_blank(),
            legend.text = element_text(size=6),
            legend.key.size = unit(0.15, "in"),
            panel.border = element_rect(color = "lightgray", fill = NA, size = 0.5),
            plot.title = element_text(hjust = 0.5)) +
      guides(fill = guide_legend(nrow = 2))
  
  return(lplot)
} 
```

```{r fig.width=6.5, fig.height=5}
return_loadings_plot(filter(results, Talker=='VF27A', abs(Loading) > 0.45))

ggsave('../../../text/figures/ch3_pca_vf27a_vert5in.png', width = 6.5, height = 5)

```

```{r fig.height=6.5, fig.width=5}
subset <- results %>%
    filter(Talker=='VF32A', abs(Loading) > 0.45) %>%
    mutate(Loading= abs(Loading),
           Variable = str_replace(Variable, '_sd', ' s.d.'),
           Variable = str_replace(Variable, 'H1H2c', 'H1*-H2*'),
           Variable = str_replace(Variable, 'H2H4c', 'H2*-H4*'),
           Variable = str_replace(Variable, 'H42Kc', 'H4*-H2kHz*'),
           Variable = str_replace(Variable, 'H2KH5Kc', 'H2kHz-H5kHz*'))
  
ggplot(subset, aes(y=Loading, x=Bar_Order, fill=Category, label=Variable)) +
      geom_col() +
      scale_fill_viridis_d(option='magma', begin = 0, end=0.75) +
      geom_text(nudge_y = -0.5*(subset$Loading), colour = "white", fontface = "bold", size=1.9)+
      #geom_label(aes(label=paste('Var:\n', round(Variance,3))), x= 0.6*max(subset$Bar_Order), y=-0.15, size=1.9, fill='white') +
      coord_flip() +
    
      facet_grid(Var_Order~Language) +
      theme_clean() +
      ylab('Loading (absolute value)') +
      xlab('') +
      theme(strip.text = element_text(face='bold', size=6),
            axis.text.y = element_blank(),
            axis.ticks.y = element_blank(),
            axis.title.y = element_blank(),
            legend.position = 'bottom',
            legend.title = element_blank(),
            legend.text = element_text(size=6),
            legend.key.size = unit(0.15, "in"),
            panel.border = element_rect(color = "lightgray", fill = NA, size = 0.5),
            plot.title = element_text(hjust = 0.5)) 

ggsave('../../../text/figures/ch3_pca_vf32a_vert5in.png', width = 5, height = 6.5)

```










```{r}
results %>%
  filter(abs(Loading)>0.45) %>%
  select(Talker, Language, Variable, Variance, Var_Order) %>%
  mutate(Variance = round(Variance,2)) %>%
  pivot_wider(names_from = Variable, values_from = Variable) %>%
  group_by(Talker, Language) %>%
  summarize(n=n(), sv = sum(Variance)) %>%
  ungroup()  %>%
  pivot_wider(names_from = Language, values_from = n:sv) 
  # write_csv('components_variances.csv')
```

```{r}
results %>%
  filter(abs(Loading)>0.45) %>%
  select(Talker, Language, Variable, Variance, Var_Order) %>%
  pivot_wider(names_from = Variable, values_from = Variable) %>%
  group_by(Talker, Language) %>%
  summarize(n=n()) %>%
  pivot_wider(names_from = Language, values_from = n) %>%
  mutate(d = as_factor(abs(Cantonese-English)) )%>%
  group_by(d) %>%
  summarise(n())
```

This is a bit messy, but its a useful structure for exploring the components.. a little better than it was
```{r}
results %>%
  filter(abs(Loading)>0.45) %>%
  select(Talker, Language, Variable, Variance, Var_Order) %>%
  pivot_wider(names_from = Variable, values_from = Variable) %>%
  select(Talker, Language, Variance, F0, F0_sd, F1, F1_sd, F2, F2_sd, F3, F3_sd, 
         F4, F4_sd, H1H2c, H1H2c_sd, H2H4c, H2H4c_sd, H2KH5Kc, H2KH5Kc_sd, 
         H42Kc, H42Kc_sd, CPP, CPP_sd, Energy, Energy_sd, SHR, SHR_sd
         ) %>%
  group_by(Talker, F0, F0_sd, F1, F1_sd, F2, F2_sd, F3, F3_sd, F4, F4_sd, H1H2c, 
           H1H2c_sd, H2H4c, H2H4c_sd, H2KH5Kc, H2KH5Kc_sd, H42Kc, H42Kc_sd, CPP, 
           CPP_sd, Energy, Energy_sd, SHR, SHR_sd
           ) %>%
  unite('Component', F0:SHR_sd, na.rm=TRUE, sep = " | ") %>%
  group_by(Talker, Component) %>% 
  summarise(n = n()) %>%
  group_by(Talker) %>%
  mutate(shared = n==2) %>%
  summarise(shared_count = sum(shared), shared_prop=2*sum(shared)/sum(n))
  # write_csv('shared_comps.csv')
    # ungroup() %>%
  # summarise(min(shared_count), mean(shared_count), median(shared_count), max(shared_count),
  #           min(shared_prop), mean(shared_prop), median(shared_prop), max(shared_prop))

```

0.333--0.9167, M=0.667

```{r}
results %>%
  filter(abs(Loading)>0.45) %>%
  select(Talker, Language, Variable, Variance, Var_Order) %>%
  pivot_wider(names_from = Variable, values_from = Variable) %>%
  select(Talker, Language, Variance, F0, F0_sd, F1, F1_sd, F2, F2_sd, F3, F3_sd, 
         F4, F4_sd, H1H2c, H1H2c_sd, H2H4c, H2H4c_sd, H2KH5Kc, H2KH5Kc_sd, 
         H42Kc, H42Kc_sd, CPP, CPP_sd, Energy, Energy_sd, SHR, SHR_sd
         ) %>%
  group_by(Talker, F0, F0_sd, F1, F1_sd, F2, F2_sd, F3, F3_sd, F4, F4_sd, H1H2c, 
           H1H2c_sd, H2H4c, H2H4c_sd, H2KH5Kc, H2KH5Kc_sd, H42Kc, H42Kc_sd, CPP, 
           CPP_sd, Energy, Energy_sd, SHR, SHR_sd
           ) %>%
  unite('Component', F0:SHR_sd, na.rm=TRUE, sep = " | ") %>%
  group_by(Talker, Component) %>% 
  summarise(n = n()) %>%
  group_by(Talker) %>%
  mutate(shared = n==2) %>%
  summarise(shared_count = sum(shared), shared_prop=2*sum(shared)/sum(n))

```

```{r fig.width= 12, fig.height=6.5}
results %>%
  filter(abs(Loading)>0.45) %>%
  select(Talker, Language, Variable, Variance, Var_Order) %>%
  mutate(Variance = round(Variance, 3)) %>%
  pivot_wider(names_from = Variable, values_from = Variable) %>%
  select(Talker, Language, Variance, F0, F0_sd, F1, F1_sd, F2, F2_sd, F3, F3_sd, 
         F4, F4_sd, H1H2c, H1H2c_sd, H2H4c, H2H4c_sd, H2KH5Kc, H2KH5Kc_sd, 
         H42Kc, H42Kc_sd, CPP, CPP_sd, Energy, Energy_sd, SHR, SHR_sd
         ) %>%
  group_by(Talker, F0, F0_sd, F1, F1_sd, F2, F2_sd, F3, F3_sd, F4, F4_sd, H1H2c, 
           H1H2c_sd, H2H4c, H2H4c_sd, H2KH5Kc, H2KH5Kc_sd, H42Kc, H42Kc_sd, CPP, 
           CPP_sd, Energy, Energy_sd, SHR, SHR_sd
           ) %>%
  unite('Component', F0:SHR_sd, na.rm=TRUE, sep = " | ") %>%
  mutate(Component = str_replace_all(Component, '_sd', ' s.d.')) %>%
  group_by(Language, Component) %>%
  summarise(n=n(), minV = min(Variance), maxV = max(Variance)) %>%
  arrange(desc(maxV), Component) %>%
  ungroup()
  # write_csv('component_summary.csv')
 #  filter(n>10) %>%
 # ggplot(aes(y=Component, xmin=minV, xmax=maxV, color=Language)) +
 #  
 #  geom_linerange() +
 #  scale_color_viridis_d(option = 'magma', begin=0.9, end=0) +
 #    theme_clean()+
 #    theme(legend.position = 'none',
 #          panel.border = element_rect(color='black',fill=NA),
 #          strip.text = element_text(size=14, face='bold'))
```


---
